{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436b0ffd-890b-477c-859d-7a1965ab08d9",
   "metadata": {},
   "source": [
    "### `Soft Actor-Critic` using `Snapbot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3966cc7e-a2c5-4349-b605-77de1eddd9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "import sys,mujoco\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('KU-DATA403-simulator-tutorials/package/helper/')\n",
    "sys.path.append('KU-DATA403-simulator-tutorials/package/mujoco_usage/')\n",
    "sys.path.append('KU-DATA403-simulator-tutorials/package/gym/')\n",
    "sys.path.append('KU-DATA403-simulator-tutorials/package/rl/')\n",
    "from mujoco_parser import *\n",
    "from slider import *\n",
    "from utility import *\n",
    "from snapbot_env import *\n",
    "from sac import *\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a258f0b-3700-4131-8dd8-297c4ea84df8",
   "metadata": {},
   "source": [
    "#### Parse `Snapbot` gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2a686f-4273-4576-a22c-8c0a294afbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:[Snapbot] dt:[0.002] HZ:[500]\n",
      "n_qpos:[25] n_qvel:[24] n_qacc:[24] n_ctrl:[8]\n",
      "\n",
      "n_body:[24]\n",
      " [0/24] [world] mass:[0.00]kg\n",
      " [1/24] [torso] mass:[0.24]kg\n",
      " [2/24] [Camera_module_1] mass:[0.06]kg\n",
      " [3/24] [Camera_module_2] mass:[0.06]kg\n",
      " [4/24] [Leg_module_1_1] mass:[0.06]kg\n",
      " [5/24] [Leg_module_1_2] mass:[0.08]kg\n",
      " [6/24] [Leg_module_1_3] mass:[0.02]kg\n",
      " [7/24] [Leg_module_1_4] mass:[0.01]kg\n",
      " [8/24] [Leg_module_1_4bar] mass:[0.01]kg\n",
      " [9/24] [Leg_module_2_1] mass:[0.06]kg\n",
      " [10/24] [Leg_module_2_2] mass:[0.08]kg\n",
      " [11/24] [Leg_module_2_3] mass:[0.02]kg\n",
      " [12/24] [Leg_module_2_4] mass:[0.01]kg\n",
      " [13/24] [Leg_module_2_4bar] mass:[0.01]kg\n",
      " [14/24] [Leg_module_4_1] mass:[0.06]kg\n",
      " [15/24] [Leg_module_4_2] mass:[0.08]kg\n",
      " [16/24] [Leg_module_4_3] mass:[0.02]kg\n",
      " [17/24] [Leg_module_4_4] mass:[0.01]kg\n",
      " [18/24] [Leg_module_4_4bar] mass:[0.01]kg\n",
      " [19/24] [Leg_module_5_1] mass:[0.06]kg\n",
      " [20/24] [Leg_module_5_2] mass:[0.08]kg\n",
      " [21/24] [Leg_module_5_3] mass:[0.02]kg\n",
      " [22/24] [Leg_module_5_4] mass:[0.01]kg\n",
      " [23/24] [Leg_module_5_4bar] mass:[0.01]kg\n",
      "body_total_mass:[1.10]kg\n",
      "\n",
      "n_geom:[24]\n",
      "geom_names:['floor', 'body', 'camera_module_1', 'camera_module_2', 'leg_module_1_1', 'leg_module_1_2', 'leg_module_1_3', 'leg_module_1_4', 'leg_module_1_4bar', 'leg_module_2_1', 'leg_module_2_2', 'leg_module_2_3', 'leg_module_2_4', 'leg_module_2_4bar', 'leg_module_4_1', 'leg_module_4_2', 'leg_module_4_3', 'leg_module_4_4', 'leg_module_4_4bar', 'leg_module_5_1', 'leg_module_5_2', 'leg_module_5_3', 'leg_module_5_4', 'leg_module_5_4bar']\n",
      "\n",
      "n_joint:[19]\n",
      " [0/19] [free] axis:[0. 0. 1.]\n",
      " [1/19] [camera_1] axis:[0. 0. 1.]\n",
      " [2/19] [camera_2] axis:[ 0.42 -0.91  0.  ]\n",
      " [3/19] [leg_1_2] axis:[0. 1. 0.]\n",
      " [4/19] [leg_1_3] axis:[1. 0. 0.]\n",
      " [5/19] [leg_1_4] axis:[1. 0. 0.]\n",
      " [6/19] [leg_1_4bar] axis:[1. 0. 0.]\n",
      " [7/19] [leg_2_2] axis:[0. 1. 0.]\n",
      " [8/19] [leg_2_3] axis:[1. 0. 0.]\n",
      " [9/19] [leg_2_4] axis:[1. 0. 0.]\n",
      " [10/19] [leg_2_4bar] axis:[1. 0. 0.]\n",
      " [11/19] [leg_4_2] axis:[0. 1. 0.]\n",
      " [12/19] [leg_4_3] axis:[1. 0. 0.]\n",
      " [13/19] [leg_4_4] axis:[1. 0. 0.]\n",
      " [14/19] [leg_4_4bar] axis:[1. 0. 0.]\n",
      " [15/19] [leg_5_2] axis:[0. 1. 0.]\n",
      " [16/19] [leg_5_3] axis:[1. 0. 0.]\n",
      " [17/19] [leg_5_4] axis:[1. 0. 0.]\n",
      " [18/19] [leg_5_4bar] axis:[1. 0. 0.]\n",
      "\n",
      "n_dof:[24] (=number of rows of Jacobian)\n",
      " [0/24] [None] attached joint:[free] body:[torso]\n",
      " [1/24] [None] attached joint:[free] body:[torso]\n",
      " [2/24] [None] attached joint:[free] body:[torso]\n",
      " [3/24] [None] attached joint:[free] body:[torso]\n",
      " [4/24] [None] attached joint:[free] body:[torso]\n",
      " [5/24] [None] attached joint:[free] body:[torso]\n",
      " [6/24] [None] attached joint:[camera_1] body:[Camera_module_1]\n",
      " [7/24] [None] attached joint:[camera_2] body:[Camera_module_2]\n",
      " [8/24] [None] attached joint:[leg_1_2] body:[Leg_module_1_2]\n",
      " [9/24] [None] attached joint:[leg_1_3] body:[Leg_module_1_3]\n",
      " [10/24] [None] attached joint:[leg_1_4] body:[Leg_module_1_4]\n",
      " [11/24] [None] attached joint:[leg_1_4bar] body:[Leg_module_1_4bar]\n",
      " [12/24] [None] attached joint:[leg_2_2] body:[Leg_module_2_2]\n",
      " [13/24] [None] attached joint:[leg_2_3] body:[Leg_module_2_3]\n",
      " [14/24] [None] attached joint:[leg_2_4] body:[Leg_module_2_4]\n",
      " [15/24] [None] attached joint:[leg_2_4bar] body:[Leg_module_2_4bar]\n",
      " [16/24] [None] attached joint:[leg_4_2] body:[Leg_module_4_2]\n",
      " [17/24] [None] attached joint:[leg_4_3] body:[Leg_module_4_3]\n",
      " [18/24] [None] attached joint:[leg_4_4] body:[Leg_module_4_4]\n",
      " [19/24] [None] attached joint:[leg_4_4bar] body:[Leg_module_4_4bar]\n",
      " [20/24] [None] attached joint:[leg_5_2] body:[Leg_module_5_2]\n",
      " [21/24] [None] attached joint:[leg_5_3] body:[Leg_module_5_3]\n",
      " [22/24] [None] attached joint:[leg_5_4] body:[Leg_module_5_4]\n",
      " [23/24] [None] attached joint:[leg_5_4bar] body:[Leg_module_5_4bar]\n",
      "\n",
      "Free joint information. n_free_joint:[1]\n",
      " [0/1] [free] body_name_attached:[torso]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[18]\n",
      " [0/18] [camera_1] range:[0.000]~[0.000]\n",
      " [1/18] [camera_2] range:[-3.140]~[0.000]\n",
      " [2/18] [leg_1_2] range:[-0.900]~[0.900]\n",
      " [3/18] [leg_1_3] range:[-0.700]~[0.700]\n",
      " [4/18] [leg_1_4] range:[0.000]~[0.000]\n",
      " [5/18] [leg_1_4bar] range:[0.000]~[0.000]\n",
      " [6/18] [leg_2_2] range:[-0.900]~[0.900]\n",
      " [7/18] [leg_2_3] range:[-0.700]~[0.700]\n",
      " [8/18] [leg_2_4] range:[0.000]~[0.000]\n",
      " [9/18] [leg_2_4bar] range:[0.000]~[0.000]\n",
      " [10/18] [leg_4_2] range:[-0.900]~[0.900]\n",
      " [11/18] [leg_4_3] range:[-0.700]~[0.700]\n",
      " [12/18] [leg_4_4] range:[0.000]~[0.000]\n",
      " [13/18] [leg_4_4bar] range:[0.000]~[0.000]\n",
      " [14/18] [leg_5_2] range:[-0.900]~[0.900]\n",
      " [15/18] [leg_5_3] range:[-0.700]~[0.700]\n",
      " [16/18] [leg_5_4] range:[0.000]~[0.000]\n",
      " [17/18] [leg_5_4bar] range:[0.000]~[0.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[8]\n",
      " [0/8] [actuator_1_2] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [1/8] [actuator_1_3] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [2/8] [actuator_2_2] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [3/8] [actuator_2_3] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [4/8] [actuator_4_2] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [5/8] [actuator_4_3] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [6/8] [actuator_5_2] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      " [7/8] [actuator_5_3] range:[-5.000]~[5.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "n_sensor:[8]\n",
      "sensor_names:['touchsensor_1_4', 'touchsensor_2_4', 'touchsensor_4_4', 'touchsensor_5_4', 'touchsensor_1_2', 'touchsensor_2_2', 'touchsensor_4_2', 'touchsensor_5_2']\n",
      "n_site:[8]\n",
      "site_names:['sensorsurf_1_2', 'sensorsurf_1_4', 'sensorsurf_2_2', 'sensorsurf_2_4', 'sensorsurf_4_2', 'sensorsurf_4_4', 'sensorsurf_5_2', 'sensorsurf_5_4']\n",
      "[Snapbot] Instantiated\n",
      "   [info] dt:[0.0200] HZ:[50], env-HZ:[500], mujoco_nstep:[10], state_dim:[35], o_dim:[70], a_dim:[8]\n",
      "   [history] total_sec:[0.20]sec, n:[10], intv_sec:[0.10]sec, intv_tick:[5]\n",
      "   [history] ticks:[0 5]\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "xml_path = 'KU-DATA403-simulator-tutorials/asset/snapbot/scene_snapbot.xml'\n",
    "env = MuJoCoParserClass(name='Snapbot',rel_xml_path=xml_path,verbose=True)\n",
    "gym = SnapbotGymClass(\n",
    "    env = env,\n",
    "    HZ  = 50,\n",
    "    history_total_sec = 0.2,\n",
    "    history_intv_sec  = 0.1,\n",
    "    VERBOSE =True,\n",
    ")\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ef748-52f2-4393-87d5-1fd8a0b3deed",
   "metadata": {},
   "source": [
    "#### `SAC` hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26839616-f629-4d84-8f90-be42dc2796a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode:[1000], max_epi_sec:[3.00], max_epi_tick:[150]\n",
      "n_warmup_epi:[10], buffer_limit:[50000], buffer_warmup:[10000]\n"
     ]
    }
   ],
   "source": [
    "n_episode         = 700 # number of total episodes (rollouts)\n",
    "max_epi_sec       = 3.0 # maximum episode length in second (IMPORTANT)\n",
    "max_epi_tick      = int(max_epi_sec*gym.HZ) # maximum episode length in tick\n",
    "n_warmup_epi      = 10 # number of warm-up episodes\n",
    "buffer_limit      = 50000 # 50000\n",
    "buffer_warmup     = buffer_limit // 5\n",
    "init_alpha        = 0.1\n",
    "max_torque        = 2.0\n",
    "# Update\n",
    "lr_actor          = 0.0004 # 0.0002 # 0.0005\n",
    "lr_alpha          = 0.0003 # 0.0003\n",
    "lr_critic         = 0.0001\n",
    "n_update_per_tick = 1 # number of updates per tick\n",
    "batch_size        = 256\n",
    "gamma             = 0.95\n",
    "tau               = 0.005\n",
    "# Debug\n",
    "print_every       = 1\n",
    "eval_every        = 1\n",
    "save_every        = 50\n",
    "RENDER_EVAL       = False # False\n",
    "print (\"n_episode:[%d], max_epi_sec:[%.2f], max_epi_tick:[%d]\"%\n",
    "       (n_episode,max_epi_sec,max_epi_tick))\n",
    "print (\"n_warmup_epi:[%d], buffer_limit:[%.d], buffer_warmup:[%d]\"%\n",
    "       (n_warmup_epi,buffer_limit,buffer_warmup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42393c-131f-4769-b110-f88c3fdd610c",
   "metadata": {},
   "source": [
    "#### Initialize networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f69ae65-97f7-4d84-984a-f74752c0faaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu' # cpu / mps / cuda\n",
    "replay_buffer = ReplayBufferClass(buffer_limit, device=device)\n",
    "actor_arg = {'obs_dim':gym.o_dim,'h_dims':[256,256],'out_dim':gym.a_dim,\n",
    "             'max_out':max_torque,'init_alpha':init_alpha,'lr_actor':lr_actor,\n",
    "             'lr_alpha':lr_alpha,'device':device}\n",
    "critic_arg = {'obs_dim':gym.o_dim,'a_dim':gym.a_dim,'h_dims':[256,256],'out_dim':1,\n",
    "              'lr_critic':lr_critic,'device':device}\n",
    "actor           = ActorClass(**actor_arg).to(device)\n",
    "critic_one      = CriticClass(**critic_arg).to(device)\n",
    "critic_two      = CriticClass(**critic_arg).to(device)\n",
    "critic_one_trgt = CriticClass(**critic_arg).to(device)\n",
    "critic_two_trgt = CriticClass(**critic_arg).to(device)\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4a57c1a-d9d3-44c9-91f0-b92df844f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor priority:[1]\n",
      "gym.env.ctrl_ranges:\n",
      " [[-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Modify floor friction priority\n",
    "env.model.geom('floor').priority = 1 # 0=>1\n",
    "print (\"Floor priority:%s\"%(env.model.geom('floor').priority))\n",
    "gym.env.ctrl_ranges[:,0] = -max_torque\n",
    "gym.env.ctrl_ranges[:,1] = +max_torque\n",
    "print (\"gym.env.ctrl_ranges:\\n\",gym.env.ctrl_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e26255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_long_jump(info):\n",
    "    x_pos = gym.env.get_p_body('torso')[0]  # Horizontal distance (primary reward)\n",
    "    z_pos = gym.env.get_p_body('torso')[2]  # Height (secondary, to ensure proper jump)\n",
    "    \n",
    "    x_vel = gym.env.get_qvel()[0]  # Forward velocity\n",
    "    z_vel = gym.env.get_qvel()[2]  # Vertical velocity\n",
    "    \n",
    "    qvel = gym.env.get_qvel()  # Joint velocities\n",
    "    qpos = gym.env.get_qpos()  # Joint positions\n",
    "    \n",
    "    # Penalize excessive rotation (keep torso stable)\n",
    "    orientation_penalty = np.linalg.norm(qpos[3:6])  # Penalize pitch/roll/yaw\n",
    "    \n",
    "    # Check if agent is airborne (no ground contact)\n",
    "    contact = gym.env.get_contact_info()\n",
    "    airborne = not any(contact)\n",
    "    \n",
    "    reward = 0.0\n",
    "\n",
    "   \n",
    "    reward += 50.0 * x_pos  # Main reward for forward progress\n",
    "    \n",
    "    #upward thrust\n",
    "    if airborne and z_pos < 0.5:  # Early jump phase\n",
    "        reward += 20.0 * max(0, z_vel)  # Reward upward thrust\n",
    "    \n",
    "    #forward velocity and yaw\n",
    "    reward += 30.0 * max(0, x_vel)  \n",
    "    if airborne:\n",
    "        target_yaw = 45.0\n",
    "        yaw_diff = abs(gym.env.get_qpos()[6] - np.radians(target_yaw))\n",
    "        reward += 25.0 * max(0, 1 - yaw_diff / np.radians(30)) \n",
    "    \n",
    "    #decent stability\n",
    "    reward -= 7.50 * orientation_penalty  \n",
    "    \n",
    "    # bonus landing after long jump\n",
    "    if not airborne and x_pos > 1.0:  # Only reward if jumped far\n",
    "        reward += 100.0  # Big bonus for successful long jump\n",
    "    \n",
    "    #make sure height is reasonable)\n",
    "    if z_pos < 0.4 and z_pos > 0.2:  # Too high = inefficient for long jump\n",
    "        reward += 25.0 * z_pos\n",
    "    \n",
    "    # 6. Leg drive efficiency (encourage synchronized rear-leg push)\n",
    "    rear_joint_vel = np.array([qvel[21], qvel[22]])  # Rear leg joints\n",
    "    rear_actuators = np.array(gym.env.get_ctrl(['actuator_5_2', 'actuator_5_3']))\n",
    "    spring_effort = np.dot(np.abs(rear_joint_vel), np.abs(rear_actuators))\n",
    "    reward += 15.0 * spring_effort  # Reward coordinated leg drive\n",
    "    \n",
    "    # Clip reward for training stability\n",
    "    reward = np.clip(reward, -10.0, 500.0)  \n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbfb24-7e9c-4a9e-a89f-72e3fcfab8c4",
   "metadata": {},
   "source": [
    "#### Train using `SAC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637ea6c-e08f-4e8f-a822-e1073fa6511d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training.\n",
      "[0/1000][0.0%]\n",
      "  reward:[2114.6] x_diff:[0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.092]\n",
      " NEW BEST JUMP: 0.092 (Episode 0)\n",
      "  [Save] Remove existing [37] pth files.\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_0.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[1/1000][0.1%]\n",
      "  reward:[2371.5] x_diff:[0.016] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.024]\n",
      "[2/1000][0.2%]\n",
      "  reward:[3125.1] x_diff:[-0.045] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.063]\n",
      "[3/1000][0.3%]\n",
      "  reward:[1733.1] x_diff:[-0.406] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.043]\n",
      "[4/1000][0.4%]\n",
      "  reward:[2264.3] x_diff:[0.068] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.176]\n",
      " NEW BEST JUMP: 0.176 (Episode 4)\n",
      "[5/1000][0.5%]\n",
      "  reward:[1283.9] x_diff:[-0.060] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.073]\n",
      "[6/1000][0.6%]\n",
      "  reward:[3065.2] x_diff:[0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.091]\n",
      "[7/1000][0.7%]\n",
      "  reward:[2039.2] x_diff:[0.118] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.128]\n",
      "[8/1000][0.8%]\n",
      "  reward:[3482.2] x_diff:[0.055] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.109]\n",
      "[9/1000][0.9%]\n",
      "  reward:[1103.6] x_diff:[0.070] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.084]\n",
      "[10/1000][1.0%]\n",
      "  reward:[368.1] x_diff:[0.047] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.134]\n",
      "[11/1000][1.1%]\n",
      "  reward:[668.7] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.081]\n",
      "[12/1000][1.2%]\n",
      "  reward:[61.0] x_diff:[0.060] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.065]\n",
      "[13/1000][1.3%]\n",
      "  reward:[177.0] x_diff:[-0.032] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.021]\n",
      "[14/1000][1.4%]\n",
      "  reward:[335.0] x_diff:[-0.043] epi_len:[75/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.005]\n",
      "[15/1000][1.5%]\n",
      "  reward:[445.8] x_diff:[0.060] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.066]\n",
      "[16/1000][1.6%]\n",
      "  reward:[99.0] x_diff:[0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.062]\n",
      "[17/1000][1.7%]\n",
      "  reward:[288.6] x_diff:[0.027] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.070]\n",
      "[18/1000][1.8%]\n",
      "  reward:[125.7] x_diff:[0.005] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.057]\n",
      "[19/1000][1.9%]\n",
      "  reward:[500.7] x_diff:[0.103] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.130]\n",
      "[20/1000][2.0%]\n",
      "  reward:[42.0] x_diff:[0.108] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.108]\n",
      "[21/1000][2.1%]\n",
      "  reward:[162.6] x_diff:[-0.023] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[22/1000][2.2%]\n",
      "  reward:[101.7] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.091]\n",
      "[23/1000][2.3%]\n",
      "  reward:[-39.9] x_diff:[0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.034]\n",
      "[24/1000][2.4%]\n",
      "  reward:[-0.2] x_diff:[0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.053]\n",
      "[25/1000][2.5%]\n",
      "  reward:[493.5] x_diff:[-0.022] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.065]\n",
      "[26/1000][2.6%]\n",
      "  reward:[1226.8] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.090]\n",
      "[27/1000][2.7%]\n",
      "  reward:[432.5] x_diff:[0.089] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.089]\n",
      "[28/1000][2.8%]\n",
      "  reward:[13.8] x_diff:[-0.037] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.020]\n",
      "[29/1000][2.9%]\n",
      "  reward:[236.7] x_diff:[0.005] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.074]\n",
      "[30/1000][3.0%]\n",
      "  reward:[-391.2] x_diff:[-0.077] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[31/1000][3.1%]\n",
      "  reward:[276.0] x_diff:[-0.076] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.027]\n",
      "[32/1000][3.2%]\n",
      "  reward:[346.8] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.022]\n",
      "[33/1000][3.3%]\n",
      "  reward:[327.9] x_diff:[-0.075] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.072]\n",
      "[34/1000][3.4%]\n",
      "  reward:[2342.2] x_diff:[0.034] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.079]\n",
      "[35/1000][3.5%]\n",
      "  reward:[332.6] x_diff:[-0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.084]\n",
      "[36/1000][3.6%]\n",
      "  reward:[-771.7] x_diff:[-0.109] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.003]\n",
      "[37/1000][3.7%]\n",
      "  reward:[2722.7] x_diff:[-0.087] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.021]\n",
      "[38/1000][3.8%]\n",
      "  reward:[-5.1] x_diff:[0.027] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.028]\n",
      "[39/1000][3.9%]\n",
      "  reward:[672.1] x_diff:[0.068] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.070]\n",
      "[40/1000][4.0%]\n",
      "  reward:[650.3] x_diff:[0.149] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.149]\n",
      "[41/1000][4.1%]\n",
      "  reward:[-425.9] x_diff:[0.030] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.040]\n",
      "[42/1000][4.2%]\n",
      "  reward:[330.7] x_diff:[-0.081] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.078]\n",
      "[43/1000][4.3%]\n",
      "  reward:[188.3] x_diff:[0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.177]\n",
      " NEW BEST JUMP: 0.177 (Episode 43)\n",
      "[44/1000][4.4%]\n",
      "  reward:[-300.6] x_diff:[-0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[45/1000][4.5%]\n",
      "  reward:[829.3] x_diff:[0.196] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.222]\n",
      " NEW BEST JUMP: 0.222 (Episode 45)\n",
      "[46/1000][4.6%]\n",
      "  reward:[65.9] x_diff:[0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.018]\n",
      "[47/1000][4.7%]\n",
      "  reward:[1174.8] x_diff:[0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.083]\n",
      "[48/1000][4.8%]\n",
      "  reward:[-307.3] x_diff:[-0.112] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.060]\n",
      "[49/1000][4.9%]\n",
      "  reward:[-43.1] x_diff:[-0.103] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.011]\n",
      "[50/1000][5.0%]\n",
      "  reward:[5561.3] x_diff:[0.066] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.128]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_50.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[51/1000][5.1%]\n",
      "  reward:[-52.2] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.053]\n",
      "[52/1000][5.2%]\n",
      "  reward:[1431.3] x_diff:[-0.270] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[53/1000][5.3%]\n",
      "  reward:[-520.2] x_diff:[-0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[54/1000][5.4%]\n",
      "  reward:[102.2] x_diff:[0.027] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.044]\n",
      "[55/1000][5.5%]\n",
      "  reward:[-356.6] x_diff:[-0.159] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.030]\n",
      "[56/1000][5.6%]\n",
      "  reward:[44.1] x_diff:[-0.026] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.032]\n",
      "[57/1000][5.7%]\n",
      "  reward:[-550.6] x_diff:[-0.143] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[58/1000][5.8%]\n",
      "  reward:[919.0] x_diff:[0.216] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.232]\n",
      " NEW BEST JUMP: 0.232 (Episode 58)\n",
      "[59/1000][5.9%]\n",
      "  reward:[518.4] x_diff:[0.123] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.178]\n",
      "[60/1000][6.0%]\n",
      "  reward:[-207.2] x_diff:[-0.047] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.022]\n",
      "[61/1000][6.1%]\n",
      "  reward:[-11.9] x_diff:[-0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.004]\n",
      "[62/1000][6.2%]\n",
      "  reward:[-531.3] x_diff:[-0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[63/1000][6.3%]\n",
      "  reward:[178.2] x_diff:[-0.075] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.000]\n",
      "[64/1000][6.4%]\n",
      "  reward:[495.4] x_diff:[0.050] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.050]\n",
      "[65/1000][6.5%]\n",
      "  reward:[157.1] x_diff:[0.108] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.108]\n",
      "[66/1000][6.6%]\n",
      "  reward:[329.8] x_diff:[0.075] epi_len:[149/150]\n",
      "  [Eval] reward:[0.257] x_diff:[-0.021] epi_len:[149/150] longest_jump:[0.075]\n",
      "[67/1000][6.7%]\n",
      "  reward:[697.7] x_diff:[0.098] epi_len:[149/150]\n",
      "  [Eval] reward:[2.457] x_diff:[0.086] epi_len:[149/150] longest_jump:[0.112]\n",
      "[68/1000][6.8%]\n",
      "  reward:[2965.4] x_diff:[0.173] epi_len:[149/150]\n",
      "  [Eval] reward:[2.612] x_diff:[0.058] epi_len:[149/150] longest_jump:[0.184]\n",
      "[69/1000][6.9%]\n",
      "  reward:[579.1] x_diff:[0.071] epi_len:[149/150]\n",
      "  [Eval] reward:[5.225] x_diff:[0.080] epi_len:[149/150] longest_jump:[0.091]\n",
      "[70/1000][7.0%]\n",
      "  reward:[4872.8] x_diff:[0.102] epi_len:[149/150]\n",
      "  [Eval] reward:[6.714] x_diff:[0.115] epi_len:[149/150] longest_jump:[0.115]\n",
      "[71/1000][7.1%]\n",
      "  reward:[379.6] x_diff:[0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.802] x_diff:[0.077] epi_len:[149/150] longest_jump:[0.081]\n",
      "[72/1000][7.2%]\n",
      "  reward:[776.1] x_diff:[0.131] epi_len:[149/150]\n",
      "  [Eval] reward:[-1420.373] x_diff:[0.004] epi_len:[149/150] longest_jump:[0.142]\n",
      "[73/1000][7.3%]\n",
      "  reward:[304.7] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-2.285] x_diff:[-0.069] epi_len:[149/150] longest_jump:[0.048]\n",
      "[74/1000][7.4%]\n",
      "  reward:[4184.7] x_diff:[-0.024] epi_len:[149/150]\n",
      "  [Eval] reward:[-7.533] x_diff:[0.000] epi_len:[149/150] longest_jump:[0.000]\n",
      "[75/1000][7.5%]\n",
      "  reward:[1079.1] x_diff:[0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.313] x_diff:[0.018] epi_len:[149/150] longest_jump:[0.058]\n",
      "[76/1000][7.6%]\n",
      "  reward:[1139.4] x_diff:[0.030] epi_len:[149/150]\n",
      "  [Eval] reward:[-1449.708] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.074]\n",
      "[77/1000][7.7%]\n",
      "  reward:[1008.5] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-1438.298] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.000]\n",
      "[78/1000][7.8%]\n",
      "  reward:[1256.8] x_diff:[0.101] epi_len:[149/150]\n",
      "  [Eval] reward:[0.974] x_diff:[-0.010] epi_len:[149/150] longest_jump:[0.137]\n",
      "[79/1000][7.9%]\n",
      "  reward:[5038.1] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-1413.070] x_diff:[-0.016] epi_len:[149/150] longest_jump:[0.022]\n",
      "[80/1000][8.0%]\n",
      "  reward:[234.3] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[3.397] x_diff:[0.040] epi_len:[149/150] longest_jump:[0.040]\n",
      "[81/1000][8.1%]\n",
      "  reward:[334.3] x_diff:[0.038] epi_len:[149/150]\n",
      "  [Eval] reward:[1.528] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.040]\n",
      "[82/1000][8.2%]\n",
      "  reward:[1758.6] x_diff:[-0.075] epi_len:[149/150]\n",
      "  [Eval] reward:[-1456.733] x_diff:[0.025] epi_len:[149/150] longest_jump:[0.025]\n",
      "[83/1000][8.3%]\n",
      "  reward:[295.9] x_diff:[0.043] epi_len:[149/150]\n",
      "  [Eval] reward:[-1455.999] x_diff:[0.033] epi_len:[149/150] longest_jump:[0.044]\n",
      "[84/1000][8.4%]\n",
      "  reward:[8516.5] x_diff:[0.103] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.076] x_diff:[0.050] epi_len:[149/150] longest_jump:[0.121]\n",
      "[85/1000][8.5%]\n",
      "  reward:[3102.5] x_diff:[0.071] epi_len:[149/150]\n",
      "  [Eval] reward:[-1356.417] x_diff:[0.025] epi_len:[149/150] longest_jump:[0.131]\n",
      "[86/1000][8.6%]\n",
      "  reward:[320.0] x_diff:[0.025] epi_len:[149/150]\n",
      "  [Eval] reward:[-14.542] x_diff:[0.094] epi_len:[149/150] longest_jump:[0.094]\n",
      "[87/1000][8.7%]\n",
      "  reward:[524.7] x_diff:[0.103] epi_len:[149/150]\n",
      "  [Eval] reward:[-9.861] x_diff:[-0.041] epi_len:[149/150] longest_jump:[0.107]\n",
      "[88/1000][8.8%]\n",
      "  reward:[279.8] x_diff:[0.023] epi_len:[149/150]\n",
      "  [Eval] reward:[1.569] x_diff:[0.031] epi_len:[149/150] longest_jump:[0.031]\n",
      "[89/1000][8.9%]\n",
      "  reward:[4358.2] x_diff:[0.034] epi_len:[149/150]\n",
      "  [Eval] reward:[-16.891] x_diff:[0.010] epi_len:[149/150] longest_jump:[0.076]\n",
      "[90/1000][9.0%]\n",
      "  reward:[1023.9] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.304] x_diff:[0.004] epi_len:[149/150] longest_jump:[0.031]\n",
      "[91/1000][9.1%]\n",
      "  reward:[1052.6] x_diff:[0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.881] x_diff:[0.016] epi_len:[149/150] longest_jump:[0.022]\n",
      "[92/1000][9.2%]\n",
      "  reward:[1082.7] x_diff:[0.023] epi_len:[149/150]\n",
      "  [Eval] reward:[-1077.490] x_diff:[0.095] epi_len:[149/150] longest_jump:[0.095]\n",
      "[93/1000][9.3%]\n",
      "  reward:[1331.0] x_diff:[0.093] epi_len:[149/150]\n",
      "  [Eval] reward:[-16.704] x_diff:[0.025] epi_len:[149/150] longest_jump:[0.128]\n",
      "[94/1000][9.4%]\n",
      "  reward:[3264.4] x_diff:[-0.059] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.080] x_diff:[-0.005] epi_len:[149/150] longest_jump:[0.013]\n",
      "[95/1000][9.5%]\n",
      "  reward:[9602.7] x_diff:[0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-16.929] x_diff:[0.018] epi_len:[149/150] longest_jump:[0.037]\n",
      "[96/1000][9.6%]\n",
      "  reward:[29009.1] x_diff:[-0.016] epi_len:[149/150]\n",
      "  [Eval] reward:[-30.479] x_diff:[-0.035] epi_len:[149/150] longest_jump:[0.070]\n",
      "[97/1000][9.7%]\n",
      "  reward:[33754.1] x_diff:[-0.044] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.480] x_diff:[-0.030] epi_len:[149/150] longest_jump:[0.014]\n",
      "[98/1000][9.8%]\n",
      "  reward:[32427.6] x_diff:[-0.031] epi_len:[149/150]\n",
      "  [Eval] reward:[-32.113] x_diff:[-0.058] epi_len:[149/150] longest_jump:[0.012]\n",
      "[99/1000][9.9%]\n",
      "  reward:[32020.8] x_diff:[-0.047] epi_len:[149/150]\n",
      "  [Eval] reward:[-50.722] x_diff:[-0.038] epi_len:[149/150] longest_jump:[0.009]\n",
      "[100/1000][10.0%]\n",
      "  reward:[29968.3] x_diff:[-0.039] epi_len:[149/150]\n",
      "  [Eval] reward:[-49.487] x_diff:[-0.026] epi_len:[149/150] longest_jump:[0.008]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_100.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[101/1000][10.1%]\n",
      "  reward:[1705.0] x_diff:[-0.073] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.968] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.020]\n",
      "[102/1000][10.2%]\n",
      "  reward:[5537.0] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.625] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.008]\n",
      "[103/1000][10.3%]\n",
      "  reward:[1629.9] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.751] x_diff:[-0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[104/1000][10.4%]\n",
      "  reward:[2118.5] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.767] x_diff:[-0.006] epi_len:[149/150] longest_jump:[0.008]\n",
      "[105/1000][10.5%]\n",
      "  reward:[6096.7] x_diff:[-0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.911] x_diff:[-0.008] epi_len:[149/150] longest_jump:[0.008]\n",
      "[106/1000][10.6%]\n",
      "  reward:[8313.5] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.639] x_diff:[-0.000] epi_len:[149/150] longest_jump:[0.008]\n",
      "[107/1000][10.7%]\n",
      "  reward:[283.0] x_diff:[-0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.713] x_diff:[-0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[108/1000][10.8%]\n",
      "  reward:[278.9] x_diff:[-0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.650] x_diff:[-0.000] epi_len:[149/150] longest_jump:[0.008]\n",
      "[109/1000][10.9%]\n",
      "  reward:[3830.3] x_diff:[0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.692] x_diff:[-0.006] epi_len:[149/150] longest_jump:[0.008]\n",
      "[110/1000][11.0%]\n",
      "  reward:[3575.1] x_diff:[0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.461] x_diff:[0.009] epi_len:[149/150] longest_jump:[0.009]\n",
      "[111/1000][11.1%]\n",
      "  reward:[3071.8] x_diff:[-0.005] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.297] x_diff:[-0.010] epi_len:[149/150] longest_jump:[0.012]\n",
      "[112/1000][11.2%]\n",
      "  reward:[4037.2] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.257] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.012]\n",
      "[113/1000][11.3%]\n",
      "  reward:[3979.8] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.366] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.010]\n",
      "[114/1000][11.4%]\n",
      "  reward:[3732.0] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.336] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.009]\n",
      "[115/1000][11.5%]\n",
      "  reward:[3883.0] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.300] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.009]\n",
      "[116/1000][11.6%]\n",
      "  reward:[3889.3] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.264] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.009]\n",
      "[117/1000][11.7%]\n",
      "  reward:[3700.1] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.544] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[118/1000][11.8%]\n",
      "  reward:[3717.4] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.441] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[119/1000][11.9%]\n",
      "  reward:[3703.2] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.516] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[120/1000][12.0%]\n",
      "  reward:[3748.5] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.383] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[121/1000][12.1%]\n",
      "  reward:[722.8] x_diff:[0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.289] x_diff:[-0.010] epi_len:[149/150] longest_jump:[0.069]\n",
      "[122/1000][12.2%]\n",
      "  reward:[3481.8] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.519] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.010]\n",
      "[123/1000][12.3%]\n",
      "  reward:[3411.7] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.151] x_diff:[-0.010] epi_len:[149/150] longest_jump:[0.011]\n",
      "[124/1000][12.4%]\n",
      "  reward:[3476.2] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.561] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.010]\n",
      "[125/1000][12.5%]\n",
      "  reward:[3493.0] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.405] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.011]\n",
      "[126/1000][12.6%]\n",
      "  reward:[3486.4] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.594] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.011]\n",
      "[127/1000][12.7%]\n",
      "  reward:[3424.6] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.540] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.011]\n",
      "[128/1000][12.8%]\n",
      "  reward:[3194.7] x_diff:[0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.380] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.087]\n",
      "[129/1000][12.9%]\n",
      "  reward:[3362.1] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.645] x_diff:[-0.010] epi_len:[149/150] longest_jump:[0.011]\n",
      "[130/1000][13.0%]\n",
      "  reward:[3457.8] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.435] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.011]\n",
      "[131/1000][13.1%]\n",
      "  reward:[3463.2] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.431] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.011]\n",
      "[132/1000][13.2%]\n",
      "  reward:[1187.8] x_diff:[-0.021] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.372] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.099]\n",
      "[133/1000][13.3%]\n",
      "  reward:[3357.1] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.613] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.011]\n",
      "[134/1000][13.4%]\n",
      "  reward:[3366.4] x_diff:[-0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.587] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.011]\n",
      "[135/1000][13.5%]\n",
      "  reward:[3403.4] x_diff:[-0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.610] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.011]\n",
      "[136/1000][13.6%]\n",
      "  reward:[3302.0] x_diff:[-0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-36.398] x_diff:[0.023] epi_len:[149/150] longest_jump:[0.023]\n",
      "[137/1000][13.7%]\n",
      "  reward:[3466.4] x_diff:[0.027] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.413] x_diff:[0.048] epi_len:[149/150] longest_jump:[0.048]\n",
      "[138/1000][13.8%]\n",
      "  reward:[3392.2] x_diff:[0.033] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.467] x_diff:[-0.017] epi_len:[149/150] longest_jump:[0.065]\n",
      "[139/1000][13.9%]\n",
      "  reward:[3351.5] x_diff:[-0.017] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.390] x_diff:[0.038] epi_len:[149/150] longest_jump:[0.038]\n",
      "[140/1000][14.0%]\n",
      "  reward:[3441.0] x_diff:[0.037] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.439] x_diff:[0.038] epi_len:[149/150] longest_jump:[0.076]\n",
      "[141/1000][14.1%]\n",
      "  reward:[3440.3] x_diff:[0.037] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.070] x_diff:[0.045] epi_len:[149/150] longest_jump:[0.076]\n",
      "[142/1000][14.2%]\n",
      "  reward:[2675.7] x_diff:[-0.040] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.028] x_diff:[0.020] epi_len:[149/150] longest_jump:[0.046]\n",
      "[143/1000][14.3%]\n",
      "  reward:[3337.8] x_diff:[0.031] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.701] x_diff:[0.005] epi_len:[149/150] longest_jump:[0.076]\n",
      "[144/1000][14.4%]\n",
      "  reward:[2722.2] x_diff:[0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.787] x_diff:[0.009] epi_len:[149/150] longest_jump:[0.072]\n",
      "[145/1000][14.5%]\n",
      "  reward:[2952.6] x_diff:[0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.555] x_diff:[0.010] epi_len:[149/150] longest_jump:[0.074]\n",
      "[146/1000][14.6%]\n",
      "  reward:[2714.9] x_diff:[0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.532] x_diff:[0.010] epi_len:[149/150] longest_jump:[0.072]\n",
      "[147/1000][14.7%]\n",
      "  reward:[2670.8] x_diff:[0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.601] x_diff:[0.009] epi_len:[149/150] longest_jump:[0.072]\n",
      "[148/1000][14.8%]\n",
      "  reward:[2617.2] x_diff:[0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.623] x_diff:[0.008] epi_len:[149/150] longest_jump:[0.072]\n",
      "[149/1000][14.9%]\n",
      "  reward:[2573.3] x_diff:[0.008] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.121] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.071]\n",
      "[150/1000][15.0%]\n",
      "  reward:[2091.3] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.144] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.066]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_150.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[151/1000][15.1%]\n",
      "  reward:[2088.9] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.077] x_diff:[0.008] epi_len:[149/150] longest_jump:[0.065]\n",
      "[152/1000][15.2%]\n",
      "  reward:[2093.9] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.119] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.066]\n",
      "[153/1000][15.3%]\n",
      "  reward:[2111.3] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.079] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.066]\n",
      "[154/1000][15.4%]\n",
      "  reward:[2114.9] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.109] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.066]\n",
      "[155/1000][15.5%]\n",
      "  reward:[2099.6] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.706] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.066]\n",
      "[156/1000][15.6%]\n",
      "  reward:[1583.3] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.729] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[157/1000][15.7%]\n",
      "  reward:[2208.1] x_diff:[0.112] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.734] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.118]\n",
      "[158/1000][15.8%]\n",
      "  reward:[1610.1] x_diff:[0.005] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.721] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[159/1000][15.9%]\n",
      "  reward:[1576.8] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.728] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.061]\n",
      "[160/1000][16.0%]\n",
      "  reward:[1594.0] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.729] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[161/1000][16.1%]\n",
      "  reward:[1605.4] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.729] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[162/1000][16.2%]\n",
      "  reward:[1607.4] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.724] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.061]\n",
      "[163/1000][16.3%]\n",
      "  reward:[1504.1] x_diff:[0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.770] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[164/1000][16.4%]\n",
      "  reward:[1589.8] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.775] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[165/1000][16.5%]\n",
      "  reward:[1583.2] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.731] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[166/1000][16.6%]\n",
      "  reward:[1624.5] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-39.719] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[167/1000][16.7%]\n",
      "  reward:[1630.4] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.747] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.061]\n",
      "[168/1000][16.8%]\n",
      "  reward:[1583.9] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.710] x_diff:[0.007] epi_len:[149/150] longest_jump:[0.061]\n",
      "[169/1000][16.9%]\n",
      "  reward:[1596.2] x_diff:[0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.761] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[170/1000][17.0%]\n",
      "  reward:[1595.0] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.776] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[171/1000][17.1%]\n",
      "  reward:[1540.0] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.754] x_diff:[0.006] epi_len:[149/150] longest_jump:[0.061]\n",
      "[172/1000][17.2%]\n",
      "  reward:[1596.2] x_diff:[0.006] epi_len:[149/150]\n",
      "  [Eval] reward:[-5.113] x_diff:[0.051] epi_len:[149/150] longest_jump:[0.061]\n",
      "[173/1000][17.3%]\n",
      "  reward:[1140.9] x_diff:[0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.212] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[174/1000][17.4%]\n",
      "  reward:[1145.2] x_diff:[0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.217] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[175/1000][17.5%]\n",
      "  reward:[1127.5] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-5.110] x_diff:[0.051] epi_len:[149/150] longest_jump:[0.062]\n",
      "[176/1000][17.6%]\n",
      "  reward:[1136.3] x_diff:[0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.213] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[177/1000][17.7%]\n",
      "  reward:[1139.6] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.219] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[178/1000][17.8%]\n",
      "  reward:[1161.8] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.226] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[179/1000][17.9%]\n",
      "  reward:[1147.4] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.243] x_diff:[0.054] epi_len:[149/150] longest_jump:[0.062]\n",
      "[180/1000][18.0%]\n",
      "  reward:[1144.9] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.223] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[181/1000][18.1%]\n",
      "  reward:[1155.5] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.191] x_diff:[0.053] epi_len:[149/150] longest_jump:[0.062]\n",
      "[182/1000][18.2%]\n",
      "  reward:[1151.5] x_diff:[0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.224] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[183/1000][18.3%]\n",
      "  reward:[1161.2] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.212] x_diff:[0.052] epi_len:[149/150] longest_jump:[0.062]\n",
      "[184/1000][18.4%]\n",
      "  reward:[1143.3] x_diff:[0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.242] x_diff:[0.054] epi_len:[149/150] longest_jump:[0.062]\n",
      "[185/1000][18.5%]\n",
      "  reward:[1135.3] x_diff:[0.054] epi_len:[149/150]\n",
      "  [Eval] reward:[-5.108] x_diff:[0.051] epi_len:[149/150] longest_jump:[0.062]\n",
      "[186/1000][18.6%]\n",
      "  reward:[1146.6] x_diff:[0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-5.194] x_diff:[0.048] epi_len:[149/150] longest_jump:[0.062]\n",
      "[187/1000][18.7%]\n",
      "  reward:[1166.8] x_diff:[0.070] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.641] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.070]\n",
      "[188/1000][18.8%]\n",
      "  reward:[1135.3] x_diff:[0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.641] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.064]\n",
      "[189/1000][18.9%]\n",
      "  reward:[1132.1] x_diff:[0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-5.768] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.064]\n",
      "[190/1000][19.0%]\n",
      "  reward:[1134.3] x_diff:[0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.770] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.065]\n",
      "[191/1000][19.1%]\n",
      "  reward:[1155.9] x_diff:[0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.893] x_diff:[0.065] epi_len:[149/150] longest_jump:[0.065]\n",
      "[192/1000][19.2%]\n",
      "  reward:[1147.2] x_diff:[0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.915] x_diff:[0.066] epi_len:[149/150] longest_jump:[0.066]\n",
      "[193/1000][19.3%]\n",
      "  reward:[1224.2] x_diff:[0.066] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.905] x_diff:[0.065] epi_len:[149/150] longest_jump:[0.067]\n",
      "[194/1000][19.4%]\n",
      "  reward:[1230.8] x_diff:[0.065] epi_len:[149/150]\n",
      "  [Eval] reward:[-15.895] x_diff:[0.065] epi_len:[149/150] longest_jump:[0.066]\n",
      "[195/1000][19.5%]\n",
      "  reward:[1208.8] x_diff:[0.065] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.328] x_diff:[0.072] epi_len:[149/150] longest_jump:[0.072]\n",
      "[196/1000][19.6%]\n",
      "  reward:[1679.0] x_diff:[0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.820] x_diff:[0.067] epi_len:[149/150] longest_jump:[0.074]\n",
      "[197/1000][19.7%]\n",
      "  reward:[293.1] x_diff:[0.065] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.883] x_diff:[0.065] epi_len:[149/150] longest_jump:[0.080]\n",
      "[198/1000][19.8%]\n",
      "  reward:[822.0] x_diff:[-0.063] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.679] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.064]\n",
      "[199/1000][19.9%]\n",
      "  reward:[349.8] x_diff:[0.066] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.393] x_diff:[0.076] epi_len:[149/150] longest_jump:[0.081]\n",
      "[200/1000][20.0%]\n",
      "  reward:[547.6] x_diff:[0.070] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.775] x_diff:[0.069] epi_len:[149/150] longest_jump:[0.083]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_200.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[201/1000][20.1%]\n",
      "  reward:[965.3] x_diff:[0.078] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.463] x_diff:[0.067] epi_len:[149/150] longest_jump:[0.086]\n",
      "[202/1000][20.2%]\n",
      "  reward:[310.7] x_diff:[0.066] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.603] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.078]\n",
      "[203/1000][20.3%]\n",
      "  reward:[397.2] x_diff:[0.065] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.320] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.078]\n",
      "[204/1000][20.4%]\n",
      "  reward:[820.8] x_diff:[0.063] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.290] x_diff:[0.078] epi_len:[149/150] longest_jump:[0.078]\n",
      "[205/1000][20.5%]\n",
      "  reward:[727.4] x_diff:[-0.040] epi_len:[125/150]\n",
      "  [Eval] reward:[-17.437] x_diff:[0.073] epi_len:[149/150] longest_jump:[0.073]\n",
      "[206/1000][20.6%]\n",
      "  reward:[2668.7] x_diff:[0.072] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.782] x_diff:[0.069] epi_len:[149/150] longest_jump:[0.079]\n",
      "[207/1000][20.7%]\n",
      "  reward:[492.6] x_diff:[0.061] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.712] x_diff:[0.065] epi_len:[149/150] longest_jump:[0.079]\n",
      "[208/1000][20.8%]\n",
      "  reward:[916.8] x_diff:[0.065] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.796] x_diff:[0.064] epi_len:[149/150] longest_jump:[0.070]\n",
      "[209/1000][20.9%]\n",
      "  reward:[1448.0] x_diff:[0.063] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.827] x_diff:[0.063] epi_len:[149/150] longest_jump:[0.070]\n",
      "[210/1000][21.0%]\n",
      "  reward:[957.5] x_diff:[0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.160] x_diff:[0.050] epi_len:[149/150] longest_jump:[0.069]\n",
      "[211/1000][21.1%]\n",
      "  reward:[885.8] x_diff:[0.043] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.455] x_diff:[0.028] epi_len:[149/150] longest_jump:[0.067]\n",
      "[212/1000][21.2%]\n",
      "  reward:[1664.7] x_diff:[0.030] epi_len:[149/150]\n",
      "  [Eval] reward:[-27.587] x_diff:[-0.001] epi_len:[149/150] longest_jump:[0.054]\n",
      "[213/1000][21.3%]\n",
      "  reward:[3632.4] x_diff:[0.117] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.759] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.121]\n",
      "[214/1000][21.4%]\n",
      "  reward:[1604.7] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.687] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.011]\n",
      "[215/1000][21.5%]\n",
      "  reward:[1637.4] x_diff:[-0.021] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.742] x_diff:[-0.017] epi_len:[149/150] longest_jump:[0.011]\n",
      "[216/1000][21.6%]\n",
      "  reward:[1658.6] x_diff:[-0.017] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.261] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.011]\n",
      "[217/1000][21.7%]\n",
      "  reward:[1631.3] x_diff:[0.072] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.268] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.092]\n",
      "[218/1000][21.8%]\n",
      "  reward:[1710.7] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.270] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.013]\n",
      "[219/1000][21.9%]\n",
      "  reward:[1724.2] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.270] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.013]\n",
      "[220/1000][22.0%]\n",
      "  reward:[1615.5] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.302] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.013]\n",
      "[221/1000][22.1%]\n",
      "  reward:[1758.3] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.296] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.012]\n",
      "[222/1000][22.2%]\n",
      "  reward:[1702.6] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.423] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.013]\n",
      "[223/1000][22.3%]\n",
      "  reward:[1705.8] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.319] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.012]\n",
      "[224/1000][22.4%]\n",
      "  reward:[1697.2] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.136] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.013]\n",
      "[225/1000][22.5%]\n",
      "  reward:[1761.9] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.378] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.014]\n",
      "[226/1000][22.6%]\n",
      "  reward:[1692.1] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.864] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.012]\n",
      "[227/1000][22.7%]\n",
      "  reward:[1741.4] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.526] x_diff:[-0.016] epi_len:[149/150] longest_jump:[0.010]\n",
      "[228/1000][22.8%]\n",
      "  reward:[1772.2] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.421] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[229/1000][22.9%]\n",
      "  reward:[1762.2] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.430] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.011]\n",
      "[230/1000][23.0%]\n",
      "  reward:[1739.8] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.446] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[231/1000][23.1%]\n",
      "  reward:[1748.9] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.264] x_diff:[-0.010] epi_len:[149/150] longest_jump:[0.010]\n",
      "[232/1000][23.2%]\n",
      "  reward:[1788.1] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.462] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.011]\n",
      "[233/1000][23.3%]\n",
      "  reward:[1763.6] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.581] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.010]\n",
      "[234/1000][23.4%]\n",
      "  reward:[1756.5] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.502] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.010]\n",
      "[235/1000][23.5%]\n",
      "  reward:[2214.2] x_diff:[0.130] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.517] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.130]\n",
      "[236/1000][23.6%]\n",
      "  reward:[1740.2] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.577] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.010]\n",
      "[237/1000][23.7%]\n",
      "  reward:[1740.8] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.527] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.010]\n",
      "[238/1000][23.8%]\n",
      "  reward:[984.7] x_diff:[-0.082] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.561] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.000]\n",
      "[239/1000][23.9%]\n",
      "  reward:[1756.4] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.602] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.010]\n",
      "[240/1000][24.0%]\n",
      "  reward:[1742.0] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.676] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.009]\n",
      "[241/1000][24.1%]\n",
      "  reward:[1755.6] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.598] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.009]\n",
      "[242/1000][24.2%]\n",
      "  reward:[1750.3] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.589] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.009]\n",
      "[243/1000][24.3%]\n",
      "  reward:[1750.6] x_diff:[-0.015] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.614] x_diff:[-0.015] epi_len:[149/150] longest_jump:[0.009]\n",
      "[244/1000][24.4%]\n",
      "  reward:[1743.1] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.520] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[245/1000][24.5%]\n",
      "  reward:[1732.9] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.491] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[246/1000][24.6%]\n",
      "  reward:[2593.8] x_diff:[0.102] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.436] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.120]\n",
      "[247/1000][24.7%]\n",
      "  reward:[1858.8] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.395] x_diff:[-0.012] epi_len:[149/150] longest_jump:[0.009]\n",
      "[248/1000][24.8%]\n",
      "  reward:[1779.8] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.502] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.010]\n",
      "[249/1000][24.9%]\n",
      "  reward:[1923.2] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.533] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[250/1000][25.0%]\n",
      "  reward:[1915.8] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.250] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.009]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_250.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[251/1000][25.1%]\n",
      "  reward:[1899.5] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.523] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[252/1000][25.2%]\n",
      "  reward:[1857.0] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.537] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[253/1000][25.3%]\n",
      "  reward:[1921.2] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.449] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.009]\n",
      "[254/1000][25.4%]\n",
      "  reward:[1888.1] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.553] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[255/1000][25.5%]\n",
      "  reward:[1794.7] x_diff:[0.027] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.532] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.095]\n",
      "[256/1000][25.6%]\n",
      "  reward:[1931.9] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.507] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.009]\n",
      "[257/1000][25.7%]\n",
      "  reward:[2618.3] x_diff:[0.011] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.528] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.011]\n",
      "[258/1000][25.8%]\n",
      "  reward:[1822.0] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.535] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[259/1000][25.9%]\n",
      "  reward:[1726.3] x_diff:[-0.076] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.568] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.000]\n",
      "[260/1000][26.0%]\n",
      "  reward:[1828.6] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.522] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[261/1000][26.1%]\n",
      "  reward:[1812.0] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.506] x_diff:[-0.014] epi_len:[149/150] longest_jump:[0.009]\n",
      "[262/1000][26.2%]\n",
      "  reward:[1886.8] x_diff:[-0.014] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.467] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.009]\n",
      "[263/1000][26.3%]\n",
      "  reward:[1807.3] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.442] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.009]\n",
      "[264/1000][26.4%]\n",
      "  reward:[1725.4] x_diff:[-0.013] epi_len:[149/150]\n",
      "  [Eval] reward:[-28.299] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.009]\n",
      "[265/1000][26.5%]\n",
      "  reward:[3746.9] x_diff:[-0.008] epi_len:[149/150]\n",
      "  [Eval] reward:[-10.546] x_diff:[-0.000] epi_len:[149/150] longest_jump:[0.004]\n",
      "[266/1000][26.6%]\n",
      "  reward:[281.2] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.260] x_diff:[0.000] epi_len:[149/150] longest_jump:[0.002]\n",
      "[267/1000][26.7%]\n",
      "  reward:[281.1] x_diff:[0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.260] x_diff:[0.000] epi_len:[149/150] longest_jump:[0.003]\n",
      "[268/1000][26.8%]\n",
      "  reward:[281.1] x_diff:[0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.260] x_diff:[0.000] epi_len:[149/150] longest_jump:[0.003]\n",
      "[269/1000][26.9%]\n",
      "  reward:[281.1] x_diff:[0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.260] x_diff:[0.000] epi_len:[149/150] longest_jump:[0.003]\n",
      "[270/1000][27.0%]\n",
      "  reward:[281.0] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-7.176] x_diff:[0.005] epi_len:[149/150] longest_jump:[0.005]\n",
      "[271/1000][27.1%]\n",
      "  reward:[712.4] x_diff:[0.125] epi_len:[149/150]\n",
      "  [Eval] reward:[-41.361] x_diff:[-0.055] epi_len:[149/150] longest_jump:[0.145]\n",
      "[272/1000][27.2%]\n",
      "  reward:[12359.5] x_diff:[-0.036] epi_len:[149/150]\n",
      "  [Eval] reward:[-40.252] x_diff:[-0.039] epi_len:[149/150] longest_jump:[0.008]\n",
      "[273/1000][27.3%]\n",
      "  reward:[5715.5] x_diff:[-0.008] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.636] x_diff:[-0.000] epi_len:[149/150] longest_jump:[0.008]\n",
      "[274/1000][27.4%]\n",
      "  reward:[280.2] x_diff:[-0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-16.971] x_diff:[0.010] epi_len:[149/150] longest_jump:[0.010]\n",
      "[275/1000][27.5%]\n",
      "  reward:[291.1] x_diff:[0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.675] x_diff:[0.000] epi_len:[149/150] longest_jump:[0.010]\n",
      "[276/1000][27.6%]\n",
      "  reward:[283.8] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.146] x_diff:[0.009] epi_len:[149/150] longest_jump:[0.009]\n",
      "[277/1000][27.7%]\n",
      "  reward:[287.6] x_diff:[0.008] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.570] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.009]\n",
      "[278/1000][27.8%]\n",
      "  reward:[283.7] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.328] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.008]\n",
      "[279/1000][27.9%]\n",
      "  reward:[2612.1] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.595] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.121]\n",
      "[280/1000][28.0%]\n",
      "  reward:[283.6] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.545] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[281/1000][28.1%]\n",
      "  reward:[283.7] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.540] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[282/1000][28.2%]\n",
      "  reward:[283.9] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.533] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.008]\n",
      "[283/1000][28.3%]\n",
      "  reward:[283.5] x_diff:[0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.598] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[284/1000][28.4%]\n",
      "  reward:[283.6] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.590] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.008]\n",
      "[285/1000][28.5%]\n",
      "  reward:[283.4] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.533] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[286/1000][28.6%]\n",
      "  reward:[283.6] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.596] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.008]\n",
      "[287/1000][28.7%]\n",
      "  reward:[283.5] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.541] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[288/1000][28.8%]\n",
      "  reward:[283.5] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.601] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[289/1000][28.9%]\n",
      "  reward:[283.6] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.399] x_diff:[-0.013] epi_len:[149/150] longest_jump:[0.008]\n",
      "[290/1000][29.0%]\n",
      "  reward:[10828.9] x_diff:[-0.025] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.111] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.008]\n",
      "[291/1000][29.1%]\n",
      "  reward:[4625.7] x_diff:[-0.009] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.081] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.008]\n",
      "[292/1000][29.2%]\n",
      "  reward:[4315.4] x_diff:[-0.005] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.858] x_diff:[-0.006] epi_len:[149/150] longest_jump:[0.008]\n",
      "[293/1000][29.3%]\n",
      "  reward:[4190.9] x_diff:[-0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.796] x_diff:[-0.007] epi_len:[149/150] longest_jump:[0.008]\n",
      "[294/1000][29.4%]\n",
      "  reward:[4184.5] x_diff:[-0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.824] x_diff:[-0.006] epi_len:[149/150] longest_jump:[0.008]\n",
      "[295/1000][29.5%]\n",
      "  reward:[4292.2] x_diff:[-0.008] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.606] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.008]\n",
      "[296/1000][29.6%]\n",
      "  reward:[3664.1] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.609] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[297/1000][29.7%]\n",
      "  reward:[3662.4] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.616] x_diff:[-0.017] epi_len:[149/150] longest_jump:[0.010]\n",
      "[298/1000][29.8%]\n",
      "  reward:[1946.6] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.674] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[299/1000][29.9%]\n",
      "  reward:[1951.7] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.585] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.008]\n",
      "[300/1000][30.0%]\n",
      "  reward:[1941.0] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.632] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.008]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_300.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[301/1000][30.1%]\n",
      "  reward:[1942.4] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.687] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[302/1000][30.2%]\n",
      "  reward:[1950.1] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.659] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[303/1000][30.3%]\n",
      "  reward:[1941.6] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.725] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[304/1000][30.4%]\n",
      "  reward:[1942.0] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.633] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.008]\n",
      "[305/1000][30.5%]\n",
      "  reward:[1943.3] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.728] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[306/1000][30.6%]\n",
      "  reward:[1942.1] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.676] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[307/1000][30.7%]\n",
      "  reward:[1950.6] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.613] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.008]\n",
      "[308/1000][30.8%]\n",
      "  reward:[1944.1] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.733] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[309/1000][30.9%]\n",
      "  reward:[1944.5] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.713] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[310/1000][31.0%]\n",
      "  reward:[1943.7] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.730] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[311/1000][31.1%]\n",
      "  reward:[1950.9] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.699] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[312/1000][31.2%]\n",
      "  reward:[1950.6] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.726] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[313/1000][31.3%]\n",
      "  reward:[1950.8] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.697] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[314/1000][31.4%]\n",
      "  reward:[1950.5] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.696] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[315/1000][31.5%]\n",
      "  reward:[1950.7] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.612] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.008]\n",
      "[316/1000][31.6%]\n",
      "  reward:[1955.2] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.727] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[317/1000][31.7%]\n",
      "  reward:[1949.0] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.706] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[318/1000][31.8%]\n",
      "  reward:[1954.9] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.705] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[319/1000][31.9%]\n",
      "  reward:[1944.5] x_diff:[-0.018] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.613] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.008]\n",
      "[320/1000][32.0%]\n",
      "  reward:[1234.1] x_diff:[0.178] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.729] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.178]\n",
      "[321/1000][32.1%]\n",
      "  reward:[1950.7] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.698] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[322/1000][32.2%]\n",
      "  reward:[1950.6] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.729] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[323/1000][32.3%]\n",
      "  reward:[1979.0] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.661] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[324/1000][32.4%]\n",
      "  reward:[1950.3] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.731] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[325/1000][32.5%]\n",
      "  reward:[1950.5] x_diff:[-0.020] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.718] x_diff:[-0.020] epi_len:[149/150] longest_jump:[0.008]\n",
      "[326/1000][32.6%]\n",
      "  reward:[1942.1] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.693] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[327/1000][32.7%]\n",
      "  reward:[4002.9] x_diff:[0.166] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.593] x_diff:[-0.018] epi_len:[149/150] longest_jump:[0.166]\n",
      "[328/1000][32.8%]\n",
      "  reward:[1942.6] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.707] x_diff:[-0.019] epi_len:[149/150] longest_jump:[0.008]\n",
      "[329/1000][32.9%]\n",
      "  reward:[1954.9] x_diff:[-0.019] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.054] x_diff:[-0.011] epi_len:[149/150] longest_jump:[0.008]\n",
      "[330/1000][33.0%]\n",
      "  reward:[2352.2] x_diff:[-0.011] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.542] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.008]\n",
      "[331/1000][33.1%]\n",
      "  reward:[3678.9] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.592] x_diff:[-0.004] epi_len:[149/150] longest_jump:[0.010]\n",
      "[332/1000][33.2%]\n",
      "  reward:[3659.1] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.547] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.009]\n",
      "[333/1000][33.3%]\n",
      "  reward:[3670.3] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.526] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[334/1000][33.4%]\n",
      "  reward:[1408.3] x_diff:[0.057] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.534] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.057]\n",
      "[335/1000][33.5%]\n",
      "  reward:[1698.1] x_diff:[0.157] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.503] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.177]\n",
      "[336/1000][33.6%]\n",
      "  reward:[3676.2] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.526] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.011]\n",
      "[337/1000][33.7%]\n",
      "  reward:[3672.4] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.545] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[338/1000][33.8%]\n",
      "  reward:[3675.6] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.493] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.010]\n",
      "[339/1000][33.9%]\n",
      "  reward:[3681.1] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.506] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.010]\n",
      "[340/1000][34.0%]\n",
      "  reward:[3686.0] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.516] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.010]\n",
      "[341/1000][34.1%]\n",
      "  reward:[3664.3] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.596] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.011]\n",
      "[342/1000][34.2%]\n",
      "  reward:[3681.0] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.532] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[343/1000][34.3%]\n",
      "  reward:[3679.9] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.575] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.009]\n",
      "[344/1000][34.4%]\n",
      "  reward:[3665.0] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.544] x_diff:[-0.002] epi_len:[149/150] longest_jump:[0.010]\n",
      "[345/1000][34.5%]\n",
      "  reward:[3683.3] x_diff:[-0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.634] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[346/1000][34.6%]\n",
      "  reward:[3684.8] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.635] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[347/1000][34.7%]\n",
      "  reward:[3666.0] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.678] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.009]\n",
      "[348/1000][34.8%]\n",
      "  reward:[3662.3] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.778] x_diff:[-0.004] epi_len:[149/150] longest_jump:[0.009]\n",
      "[349/1000][34.9%]\n",
      "  reward:[3672.7] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.673] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.009]\n",
      "[350/1000][35.0%]\n",
      "  reward:[3661.7] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.728] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.009]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_350.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[351/1000][35.1%]\n",
      "  reward:[3651.2] x_diff:[-0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.784] x_diff:[-0.004] epi_len:[149/150] longest_jump:[0.010]\n",
      "[352/1000][35.2%]\n",
      "  reward:[3696.9] x_diff:[-0.004] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.921] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.008]\n",
      "[353/1000][35.3%]\n",
      "  reward:[3688.2] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-48.004] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[354/1000][35.4%]\n",
      "  reward:[3702.9] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.985] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[355/1000][35.5%]\n",
      "  reward:[3705.4] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.956] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[356/1000][35.6%]\n",
      "  reward:[3705.7] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.999] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[357/1000][35.7%]\n",
      "  reward:[3703.8] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-57.981] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[358/1000][35.8%]\n",
      "  reward:[3695.7] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.973] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[359/1000][35.9%]\n",
      "  reward:[3695.9] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.966] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[360/1000][36.0%]\n",
      "  reward:[2783.4] x_diff:[0.117] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.971] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.123]\n",
      "[361/1000][36.1%]\n",
      "  reward:[3667.0] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.947] x_diff:[0.001] epi_len:[149/150] longest_jump:[0.014]\n",
      "[362/1000][36.2%]\n",
      "  reward:[3695.8] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.941] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.014]\n",
      "[363/1000][36.3%]\n",
      "  reward:[3707.5] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.914] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.014]\n",
      "[364/1000][36.4%]\n",
      "  reward:[3707.1] x_diff:[0.001] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.928] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.014]\n",
      "[365/1000][36.5%]\n",
      "  reward:[3707.2] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.828] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.014]\n",
      "[366/1000][36.6%]\n",
      "  reward:[3709.0] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.886] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.014]\n",
      "[367/1000][36.7%]\n",
      "  reward:[3706.7] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.787] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.015]\n",
      "[368/1000][36.8%]\n",
      "  reward:[3669.6] x_diff:[0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.819] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.015]\n",
      "[369/1000][36.9%]\n",
      "  reward:[3667.7] x_diff:[0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.848] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.015]\n",
      "[370/1000][37.0%]\n",
      "  reward:[3706.4] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.879] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.015]\n",
      "[371/1000][37.1%]\n",
      "  reward:[3671.6] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-47.904] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.015]\n",
      "[372/1000][37.2%]\n",
      "  reward:[3710.4] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.781] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.015]\n",
      "[373/1000][37.3%]\n",
      "  reward:[3704.7] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.782] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.015]\n",
      "[374/1000][37.4%]\n",
      "  reward:[3664.0] x_diff:[0.003] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.883] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.015]\n",
      "[375/1000][37.5%]\n",
      "  reward:[1997.7] x_diff:[0.033] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.801] x_diff:[0.003] epi_len:[149/150] longest_jump:[0.083]\n",
      "[376/1000][37.6%]\n",
      "  reward:[3703.2] x_diff:[0.002] epi_len:[149/150]\n",
      "  [Eval] reward:[-37.866] x_diff:[0.002] epi_len:[149/150] longest_jump:[0.015]\n",
      "[377/1000][37.7%]\n",
      "  reward:[14688.7] x_diff:[0.000] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.719] x_diff:[-0.036] epi_len:[149/150] longest_jump:[0.027]\n",
      "[378/1000][37.8%]\n",
      "  reward:[17423.3] x_diff:[-0.043] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.985] x_diff:[-0.051] epi_len:[149/150] longest_jump:[0.011]\n",
      "[379/1000][37.9%]\n",
      "  reward:[16059.7] x_diff:[-0.049] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.817] x_diff:[-0.049] epi_len:[149/150] longest_jump:[0.011]\n",
      "[380/1000][38.0%]\n",
      "  reward:[18933.3] x_diff:[-0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-34.162] x_diff:[-0.072] epi_len:[149/150] longest_jump:[0.012]\n",
      "[381/1000][38.1%]\n",
      "  reward:[28089.2] x_diff:[-0.078] epi_len:[149/150]\n",
      "  [Eval] reward:[-35.096] x_diff:[-0.085] epi_len:[149/150] longest_jump:[0.011]\n",
      "[382/1000][38.2%]\n",
      "  reward:[28797.9] x_diff:[-0.101] epi_len:[149/150]\n",
      "  [Eval] reward:[-34.100] x_diff:[-0.072] epi_len:[149/150] longest_jump:[0.011]\n",
      "[383/1000][38.3%]\n",
      "  reward:[20346.3] x_diff:[-0.059] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.387] x_diff:[-0.079] epi_len:[149/150] longest_jump:[0.011]\n",
      "[384/1000][38.4%]\n",
      "  reward:[25369.4] x_diff:[-0.080] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.896] x_diff:[-0.059] epi_len:[149/150] longest_jump:[0.011]\n",
      "[385/1000][38.5%]\n",
      "  reward:[23809.9] x_diff:[-0.076] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.115] x_diff:[-0.057] epi_len:[149/150] longest_jump:[0.011]\n",
      "[386/1000][38.6%]\n",
      "  reward:[24178.1] x_diff:[-0.042] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.924] x_diff:[-0.072] epi_len:[149/150] longest_jump:[0.011]\n",
      "[387/1000][38.7%]\n",
      "  reward:[19739.6] x_diff:[-0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.877] x_diff:[-0.045] epi_len:[149/150] longest_jump:[0.010]\n",
      "[388/1000][38.8%]\n",
      "  reward:[22779.3] x_diff:[-0.057] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.848] x_diff:[-0.052] epi_len:[149/150] longest_jump:[0.010]\n",
      "[389/1000][38.9%]\n",
      "  reward:[22500.4] x_diff:[-0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.902] x_diff:[-0.073] epi_len:[149/150] longest_jump:[0.011]\n",
      "[390/1000][39.0%]\n",
      "  reward:[16252.8] x_diff:[-0.045] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.108] x_diff:[-0.040] epi_len:[149/150] longest_jump:[0.011]\n",
      "[391/1000][39.1%]\n",
      "  reward:[18337.3] x_diff:[-0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.606] x_diff:[-0.068] epi_len:[149/150] longest_jump:[0.011]\n",
      "[392/1000][39.2%]\n",
      "  reward:[23593.0] x_diff:[-0.071] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.341] x_diff:[-0.069] epi_len:[149/150] longest_jump:[0.010]\n",
      "[393/1000][39.3%]\n",
      "  reward:[22500.6] x_diff:[-0.070] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.538] x_diff:[-0.060] epi_len:[149/150] longest_jump:[0.010]\n",
      "[394/1000][39.4%]\n",
      "  reward:[19909.3] x_diff:[-0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.871] x_diff:[-0.062] epi_len:[149/150] longest_jump:[0.011]\n",
      "[395/1000][39.5%]\n",
      "  reward:[15515.5] x_diff:[-0.049] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.774] x_diff:[-0.049] epi_len:[149/150] longest_jump:[0.010]\n",
      "[396/1000][39.6%]\n",
      "  reward:[12612.7] x_diff:[-0.031] epi_len:[149/150]\n",
      "  [Eval] reward:[-17.180] x_diff:[0.008] epi_len:[149/150] longest_jump:[0.012]\n",
      "[397/1000][39.7%]\n",
      "  reward:[16676.2] x_diff:[-0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.969] x_diff:[-0.048] epi_len:[149/150] longest_jump:[0.012]\n",
      "[398/1000][39.8%]\n",
      "  reward:[18876.1] x_diff:[-0.071] epi_len:[149/150]\n",
      "  [Eval] reward:[-33.023] x_diff:[-0.064] epi_len:[149/150] longest_jump:[0.010]\n",
      "[399/1000][39.9%]\n",
      "  reward:[21371.4] x_diff:[-0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.903] x_diff:[-0.047] epi_len:[149/150] longest_jump:[0.010]\n",
      "[400/1000][40.0%]\n",
      "  reward:[21422.1] x_diff:[-0.060] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.933] x_diff:[-0.078] epi_len:[149/150] longest_jump:[0.011]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_400.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[401/1000][40.1%]\n",
      "  reward:[19738.4] x_diff:[-0.059] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.534] x_diff:[-0.067] epi_len:[149/150] longest_jump:[0.011]\n",
      "[402/1000][40.2%]\n",
      "  reward:[19995.9] x_diff:[-0.081] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.230] x_diff:[-0.062] epi_len:[149/150] longest_jump:[0.011]\n",
      "[403/1000][40.3%]\n",
      "  reward:[19617.4] x_diff:[-0.066] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.839] x_diff:[-0.072] epi_len:[149/150] longest_jump:[0.011]\n",
      "[404/1000][40.4%]\n",
      "  reward:[20611.1] x_diff:[-0.058] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.423] x_diff:[-0.064] epi_len:[149/150] longest_jump:[0.011]\n",
      "[405/1000][40.5%]\n",
      "  reward:[22274.3] x_diff:[-0.048] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.588] x_diff:[-0.071] epi_len:[149/150] longest_jump:[0.011]\n",
      "[406/1000][40.6%]\n",
      "  reward:[18762.7] x_diff:[-0.061] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.754] x_diff:[-0.073] epi_len:[149/150] longest_jump:[0.011]\n",
      "[407/1000][40.7%]\n",
      "  reward:[2202.4] x_diff:[-0.066] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.294] x_diff:[-0.044] epi_len:[149/150] longest_jump:[0.016]\n",
      "[408/1000][40.8%]\n",
      "  reward:[15114.0] x_diff:[-0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.965] x_diff:[-0.074] epi_len:[149/150] longest_jump:[0.012]\n",
      "[409/1000][40.9%]\n",
      "  reward:[17285.6] x_diff:[-0.065] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.114] x_diff:[-0.062] epi_len:[149/150] longest_jump:[0.011]\n",
      "[410/1000][41.0%]\n",
      "  reward:[16605.7] x_diff:[-0.061] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.364] x_diff:[-0.065] epi_len:[149/150] longest_jump:[0.011]\n",
      "[411/1000][41.1%]\n",
      "  reward:[18991.6] x_diff:[-0.073] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.713] x_diff:[-0.056] epi_len:[149/150] longest_jump:[0.010]\n",
      "[412/1000][41.2%]\n",
      "  reward:[17694.2] x_diff:[-0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.669] x_diff:[-0.055] epi_len:[149/150] longest_jump:[0.011]\n",
      "[413/1000][41.3%]\n",
      "  reward:[17826.5] x_diff:[-0.062] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.918] x_diff:[-0.073] epi_len:[149/150] longest_jump:[0.010]\n",
      "[414/1000][41.4%]\n",
      "  reward:[12643.6] x_diff:[-0.010] epi_len:[149/150]\n",
      "  [Eval] reward:[-18.016] x_diff:[-0.003] epi_len:[149/150] longest_jump:[0.010]\n",
      "[415/1000][41.5%]\n",
      "  reward:[15857.7] x_diff:[-0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.747] x_diff:[-0.060] epi_len:[149/150] longest_jump:[0.011]\n",
      "[416/1000][41.6%]\n",
      "  reward:[19299.1] x_diff:[-0.059] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.320] x_diff:[-0.066] epi_len:[149/150] longest_jump:[0.011]\n",
      "[417/1000][41.7%]\n",
      "  reward:[20078.1] x_diff:[-0.069] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.489] x_diff:[-0.068] epi_len:[149/150] longest_jump:[0.010]\n",
      "[418/1000][41.8%]\n",
      "  reward:[1796.2] x_diff:[-0.012] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.677] x_diff:[-0.098] epi_len:[149/150] longest_jump:[0.062]\n",
      "[419/1000][41.9%]\n",
      "  reward:[25773.7] x_diff:[-0.099] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.172] x_diff:[-0.089] epi_len:[149/150] longest_jump:[0.013]\n",
      "[420/1000][42.0%]\n",
      "  reward:[23922.9] x_diff:[-0.085] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.472] x_diff:[-0.095] epi_len:[149/150] longest_jump:[0.010]\n",
      "[421/1000][42.1%]\n",
      "  reward:[30216.5] x_diff:[-0.078] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.309] x_diff:[-0.036] epi_len:[149/150] longest_jump:[0.013]\n",
      "[422/1000][42.2%]\n",
      "  reward:[32797.0] x_diff:[-0.048] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.754] x_diff:[-0.072] epi_len:[149/150] longest_jump:[0.013]\n",
      "[423/1000][42.3%]\n",
      "  reward:[30119.7] x_diff:[-0.048] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.599] x_diff:[-0.084] epi_len:[149/150] longest_jump:[0.012]\n",
      "[424/1000][42.4%]\n",
      "  reward:[21496.0] x_diff:[-0.072] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.592] x_diff:[-0.068] epi_len:[149/150] longest_jump:[0.011]\n",
      "[425/1000][42.5%]\n",
      "  reward:[23859.9] x_diff:[-0.084] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.182] x_diff:[-0.092] epi_len:[149/150] longest_jump:[0.012]\n",
      "[426/1000][42.6%]\n",
      "  reward:[26039.0] x_diff:[-0.096] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.829] x_diff:[-0.070] epi_len:[149/150] longest_jump:[0.012]\n",
      "[427/1000][42.7%]\n",
      "  reward:[21727.7] x_diff:[-0.064] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.483] x_diff:[-0.082] epi_len:[149/150] longest_jump:[0.011]\n",
      "[428/1000][42.8%]\n",
      "  reward:[19961.9] x_diff:[-0.078] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.768] x_diff:[-0.084] epi_len:[149/150] longest_jump:[0.011]\n",
      "[429/1000][42.9%]\n",
      "  reward:[22263.7] x_diff:[-0.095] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.539] x_diff:[-0.099] epi_len:[149/150] longest_jump:[0.011]\n",
      "[430/1000][43.0%]\n",
      "  reward:[24953.1] x_diff:[-0.073] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.149] x_diff:[-0.060] epi_len:[149/150] longest_jump:[0.013]\n",
      "[431/1000][43.1%]\n",
      "  reward:[23643.7] x_diff:[-0.098] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.404] x_diff:[-0.068] epi_len:[149/150] longest_jump:[0.013]\n",
      "[432/1000][43.2%]\n",
      "  reward:[24248.1] x_diff:[-0.076] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.923] x_diff:[-0.057] epi_len:[149/150] longest_jump:[0.012]\n",
      "[433/1000][43.3%]\n",
      "  reward:[19311.2] x_diff:[-0.041] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.788] x_diff:[-0.074] epi_len:[149/150] longest_jump:[0.010]\n",
      "[434/1000][43.4%]\n",
      "  reward:[23043.7] x_diff:[-0.056] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.228] x_diff:[-0.096] epi_len:[149/150] longest_jump:[0.011]\n",
      "[435/1000][43.5%]\n",
      "  reward:[19596.5] x_diff:[-0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.783] x_diff:[-0.038] epi_len:[149/150] longest_jump:[0.012]\n",
      "[436/1000][43.6%]\n",
      "  reward:[4426.0] x_diff:[0.087] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.962] x_diff:[-0.044] epi_len:[149/150] longest_jump:[0.152]\n",
      "[437/1000][43.7%]\n",
      "  reward:[20214.3] x_diff:[-0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.163] x_diff:[-0.061] epi_len:[149/150] longest_jump:[0.010]\n",
      "[438/1000][43.8%]\n",
      "  reward:[18991.0] x_diff:[-0.016] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.671] x_diff:[-0.082] epi_len:[149/150] longest_jump:[0.012]\n",
      "[439/1000][43.9%]\n",
      "  reward:[2557.3] x_diff:[-0.098] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.937] x_diff:[-0.076] epi_len:[149/150] longest_jump:[0.005]\n",
      "[440/1000][44.0%]\n",
      "  reward:[19442.4] x_diff:[-0.028] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.046] x_diff:[-0.052] epi_len:[149/150] longest_jump:[0.013]\n",
      "[441/1000][44.1%]\n",
      "  reward:[25436.1] x_diff:[-0.067] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.581] x_diff:[-0.053] epi_len:[149/150] longest_jump:[0.013]\n",
      "[442/1000][44.2%]\n",
      "  reward:[23083.2] x_diff:[-0.083] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.920] x_diff:[-0.088] epi_len:[149/150] longest_jump:[0.013]\n",
      "[443/1000][44.3%]\n",
      "  reward:[20392.1] x_diff:[-0.068] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.431] x_diff:[-0.066] epi_len:[149/150] longest_jump:[0.011]\n",
      "[444/1000][44.4%]\n",
      "  reward:[22413.4] x_diff:[-0.090] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.180] x_diff:[-0.066] epi_len:[149/150] longest_jump:[0.012]\n",
      "[445/1000][44.5%]\n",
      "  reward:[20676.2] x_diff:[-0.053] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.979] x_diff:[-0.063] epi_len:[149/150] longest_jump:[0.012]\n",
      "[446/1000][44.6%]\n",
      "  reward:[23349.7] x_diff:[-0.100] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.805] x_diff:[-0.042] epi_len:[149/150] longest_jump:[0.013]\n",
      "[447/1000][44.7%]\n",
      "  reward:[23535.8] x_diff:[-0.090] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.716] x_diff:[-0.088] epi_len:[149/150] longest_jump:[0.011]\n",
      "[448/1000][44.8%]\n",
      "  reward:[22617.4] x_diff:[-0.076] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.520] x_diff:[-0.088] epi_len:[149/150] longest_jump:[0.012]\n",
      "[449/1000][44.9%]\n",
      "  reward:[19304.3] x_diff:[-0.042] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.671] x_diff:[-0.087] epi_len:[149/150] longest_jump:[0.012]\n",
      "[450/1000][45.0%]\n",
      "  reward:[18455.7] x_diff:[-0.051] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.750] x_diff:[-0.067] epi_len:[149/150] longest_jump:[0.012]\n",
      "  [Save] [./result/weights/sac_snapbot/longjump/episode_450.pth] saved.\n",
      "  [Save] Best jump actions saved to [./result/weights/sac_snapbot/longjump/best_jump_actions.pth].\n",
      "[451/1000][45.1%]\n",
      "  reward:[22336.4] x_diff:[-0.081] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.138] x_diff:[-0.062] epi_len:[149/150] longest_jump:[0.011]\n",
      "[452/1000][45.2%]\n",
      "  reward:[18079.1] x_diff:[-0.046] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.955] x_diff:[-0.058] epi_len:[149/150] longest_jump:[0.011]\n",
      "[453/1000][45.3%]\n",
      "  reward:[21221.7] x_diff:[-0.058] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.077] x_diff:[-0.064] epi_len:[149/150] longest_jump:[0.012]\n",
      "[454/1000][45.4%]\n",
      "  reward:[24918.9] x_diff:[-0.067] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.028] x_diff:[-0.077] epi_len:[149/150] longest_jump:[0.012]\n",
      "[455/1000][45.5%]\n",
      "  reward:[25413.5] x_diff:[-0.054] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.967] x_diff:[-0.035] epi_len:[149/150] longest_jump:[0.012]\n",
      "[456/1000][45.6%]\n",
      "  reward:[24975.7] x_diff:[-0.081] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.558] x_diff:[-0.081] epi_len:[149/150] longest_jump:[0.012]\n",
      "[457/1000][45.7%]\n",
      "  reward:[26832.2] x_diff:[-0.071] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.636] x_diff:[-0.063] epi_len:[149/150] longest_jump:[0.012]\n",
      "[458/1000][45.8%]\n",
      "  reward:[26704.8] x_diff:[-0.073] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.921] x_diff:[-0.104] epi_len:[149/150] longest_jump:[0.012]\n",
      "[459/1000][45.9%]\n",
      "  reward:[26355.1] x_diff:[-0.083] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.198] x_diff:[-0.076] epi_len:[149/150] longest_jump:[0.012]\n",
      "[460/1000][46.0%]\n",
      "  reward:[25263.3] x_diff:[-0.067] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.056] x_diff:[-0.092] epi_len:[149/150] longest_jump:[0.012]\n",
      "[461/1000][46.1%]\n",
      "  reward:[23379.5] x_diff:[-0.067] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.745] x_diff:[-0.087] epi_len:[149/150] longest_jump:[0.012]\n",
      "[462/1000][46.2%]\n",
      "  reward:[24174.4] x_diff:[-0.085] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.363] x_diff:[-0.068] epi_len:[149/150] longest_jump:[0.012]\n",
      "[463/1000][46.3%]\n",
      "  reward:[25420.1] x_diff:[-0.057] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.907] x_diff:[-0.045] epi_len:[149/150] longest_jump:[0.012]\n",
      "[464/1000][46.4%]\n",
      "  reward:[28707.6] x_diff:[-0.027] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.659] x_diff:[-0.088] epi_len:[149/150] longest_jump:[0.012]\n",
      "[465/1000][46.5%]\n",
      "  reward:[25330.7] x_diff:[-0.059] epi_len:[149/150]\n",
      "  [Eval] reward:[-19.985] x_diff:[-0.022] epi_len:[149/150] longest_jump:[0.012]\n",
      "[466/1000][46.6%]\n",
      "  reward:[24376.0] x_diff:[-0.032] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.828] x_diff:[-0.075] epi_len:[149/150] longest_jump:[0.012]\n",
      "[467/1000][46.7%]\n",
      "  reward:[26450.2] x_diff:[-0.050] epi_len:[149/150]\n",
      "  [Eval] reward:[-19.977] x_diff:[-0.027] epi_len:[149/150] longest_jump:[0.013]\n",
      "[468/1000][46.8%]\n",
      "  reward:[31522.3] x_diff:[-0.029] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.015] x_diff:[-0.052] epi_len:[149/150] longest_jump:[0.013]\n",
      "[469/1000][46.9%]\n",
      "  reward:[25207.4] x_diff:[-0.060] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.352] x_diff:[-0.031] epi_len:[149/150] longest_jump:[0.012]\n",
      "[470/1000][47.0%]\n",
      "  reward:[28500.7] x_diff:[-0.042] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.180] x_diff:[-0.065] epi_len:[149/150] longest_jump:[0.013]\n",
      "[471/1000][47.1%]\n",
      "  reward:[25648.7] x_diff:[-0.061] epi_len:[149/150]\n",
      "  [Eval] reward:[-20.571] x_diff:[-0.032] epi_len:[149/150] longest_jump:[0.012]\n",
      "[472/1000][47.2%]\n",
      "  reward:[27421.5] x_diff:[-0.058] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.624] x_diff:[-0.058] epi_len:[149/150] longest_jump:[0.013]\n",
      "[473/1000][47.3%]\n",
      "  reward:[24025.5] x_diff:[-0.087] epi_len:[149/150]\n",
      "  [Eval] reward:[-23.653] x_diff:[-0.071] epi_len:[149/150] longest_jump:[0.013]\n",
      "[474/1000][47.4%]\n",
      "  reward:[26893.0] x_diff:[-0.076] epi_len:[149/150]\n",
      "  [Eval] reward:[-19.027] x_diff:[-0.009] epi_len:[149/150] longest_jump:[0.012]\n",
      "[475/1000][47.5%]\n",
      "  reward:[30258.5] x_diff:[-0.037] epi_len:[149/150]\n",
      "  [Eval] reward:[0.394] x_diff:[-0.017] epi_len:[149/150] longest_jump:[0.013]\n",
      "[476/1000][47.6%]\n",
      "  reward:[30839.0] x_diff:[-0.044] epi_len:[149/150]\n",
      "  [Eval] reward:[-0.877] x_diff:[-0.036] epi_len:[149/150] longest_jump:[0.010]\n",
      "[477/1000][47.7%]\n",
      "  reward:[1878.0] x_diff:[0.074] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.709] x_diff:[-0.048] epi_len:[149/150] longest_jump:[0.084]\n",
      "[478/1000][47.8%]\n",
      "  reward:[29380.5] x_diff:[-0.074] epi_len:[149/150]\n",
      "  [Eval] reward:[-2.767] x_diff:[-0.066] epi_len:[149/150] longest_jump:[0.012]\n",
      "[479/1000][47.9%]\n",
      "  reward:[26655.7] x_diff:[-0.080] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.175] x_diff:[-0.055] epi_len:[149/150] longest_jump:[0.011]\n",
      "[480/1000][48.0%]\n",
      "  reward:[28212.8] x_diff:[-0.052] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.276] x_diff:[-0.082] epi_len:[149/150] longest_jump:[0.013]\n",
      "[481/1000][48.1%]\n",
      "  reward:[25532.0] x_diff:[-0.081] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.170] x_diff:[-0.082] epi_len:[149/150] longest_jump:[0.013]\n",
      "[482/1000][48.2%]\n",
      "  reward:[27676.8] x_diff:[-0.075] epi_len:[149/150]\n",
      "  [Eval] reward:[-25.872] x_diff:[-0.103] epi_len:[149/150] longest_jump:[0.012]\n",
      "[483/1000][48.3%]\n",
      "  reward:[25222.6] x_diff:[-0.063] epi_len:[149/150]\n",
      "  [Eval] reward:[-21.483] x_diff:[-0.046] epi_len:[149/150] longest_jump:[0.011]\n",
      "[484/1000][48.4%]\n",
      "  reward:[27497.6] x_diff:[-0.050] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.181] x_diff:[-0.040] epi_len:[149/150] longest_jump:[0.012]\n",
      "[485/1000][48.5%]\n",
      "  reward:[24394.1] x_diff:[-0.007] epi_len:[149/150]\n",
      "  [Eval] reward:[-24.307] x_diff:[-0.064] epi_len:[149/150] longest_jump:[0.038]\n",
      "[486/1000][48.6%]\n",
      "  reward:[27154.6] x_diff:[-0.414] epi_len:[149/150]\n",
      "  [Eval] reward:[-58.255] x_diff:[-0.337] epi_len:[149/150] longest_jump:[0.006]\n",
      "[487/1000][48.7%]\n",
      "  reward:[1599.9] x_diff:[0.041] epi_len:[149/150]\n",
      "  [Eval] reward:[-27.733] x_diff:[-0.145] epi_len:[149/150] longest_jump:[0.060]\n",
      "[488/1000][48.8%]\n",
      "  reward:[23277.4] x_diff:[-0.256] epi_len:[149/150]\n",
      "  [Eval] reward:[-22.245] x_diff:[-0.222] epi_len:[149/150] longest_jump:[0.005]\n",
      "[489/1000][48.9%]\n",
      "  reward:[27530.1] x_diff:[-0.079] epi_len:[149/150]\n",
      "  [Eval] reward:[-29.758] x_diff:[-0.178] epi_len:[149/150] longest_jump:[0.005]\n",
      "[490/1000][49.0%]\n",
      "  reward:[25838.9] x_diff:[-0.114] epi_len:[149/150]\n",
      "  [Eval] reward:[-134.585] x_diff:[-0.411] epi_len:[149/150] longest_jump:[0.006]\n",
      "[491/1000][49.1%]\n",
      "  reward:[32250.8] x_diff:[-0.376] epi_len:[149/150]\n",
      "  [Eval] reward:[-44.882] x_diff:[-0.430] epi_len:[149/150] longest_jump:[0.006]\n",
      "[492/1000][49.2%]\n",
      "  reward:[30490.8] x_diff:[-0.313] epi_len:[149/150]\n",
      "  [Eval] reward:[-38.392] x_diff:[-0.109] epi_len:[149/150] longest_jump:[0.012]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRACK_BEST_EPISODE:\n\u001b[1;32m     32\u001b[0m     current_episode_actions\u001b[38;5;241m.\u001b[39mappend(a_np\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m---> 34\u001b[0m s_prime,_,done,info \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epi_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m reward \u001b[38;5;241m=\u001b[39m reward_long_jump(info)  \u001b[38;5;66;03m#using long jump reward            \u001b[39;00m\n\u001b[1;32m     36\u001b[0m replay_buffer\u001b[38;5;241m.\u001b[39mput((s,a_np,reward,s_prime,done))\n",
      "File \u001b[0;32m/mnt/c/Users/Natha/OneDrive/Documents/Files/kuSEM2/REINFORCEMENTLEARNING/RLProject/KU-DATA403-simulator-tutorials/package/gym/snapbot_env.py:121\u001b[0m, in \u001b[0;36mSnapbotGymClass.step\u001b[0;34m(self, a, max_time)\u001b[0m\n\u001b[1;32m    118\u001b[0m yaw_torso_deg_prev \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdegrees(r2rpy(R_torso_prev)[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Run simulation for 'mujoco_nstep' steps\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmujoco_nstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Current torso position and yaw angle in degree\u001b[39;00m\n\u001b[1;32m    124\u001b[0m p_torso_curr       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mget_p_body(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorso\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/Natha/OneDrive/Documents/Files/kuSEM2/REINFORCEMENTLEARNING/RLProject/KU-DATA403-simulator-tutorials/package/mujoco_usage/mujoco_parser.py:431\u001b[0m, in \u001b[0;36mMuJoCoParserClass.step\u001b[0;34m(self, ctrl, ctrl_idxs, joint_names, nstep, increase_tick)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctrl_idxs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mctrl[:] \u001b[38;5;241m=\u001b[39m ctrl\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mctrl[ctrl_idxs] \u001b[38;5;241m=\u001b[39m ctrl\n\u001b[0;32m--> 431\u001b[0m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmj_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increase_tick: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "REMOVE_PREV_FILES = True # remove previous files\n",
    "TRACK_BEST_EPISODE = True\n",
    "best_longest_jump = -np.inf\n",
    "best_episode_data = None\n",
    "best_episode_idx = 0\n",
    "\n",
    "\n",
    "# Loop\n",
    "np.random.seed(seed=0) # fix seed\n",
    "print (\"Start training.\")\n",
    "for epi_idx in range(n_episode+1): # for each episode\n",
    "    zero_to_one = epi_idx/n_episode\n",
    "    one_to_zero = 1-zero_to_one\n",
    "\n",
    "    if TRACK_BEST_EPISODE:\n",
    "        current_episode_actions = []\n",
    "    # Reset gym\n",
    "    s = gym.reset()\n",
    "\n",
    "    # Loop\n",
    "    USE_RANDOM_POLICY = (np.random.rand()<(0.1*one_to_zero)) or (epi_idx < n_warmup_epi)\n",
    "    reward_total,reward_forward = 0.0,0.0\n",
    "    longest_jump = 0.0\n",
    "    for tick in range(max_epi_tick): # for each tick in an episode\n",
    "        if USE_RANDOM_POLICY:\n",
    "            a_np = gym.sample_action()\n",
    "        else:\n",
    "            a,log_prob = actor(np2torch(s,device=device))\n",
    "            a_np = torch2np(a)\n",
    "        # Step\n",
    "        if TRACK_BEST_EPISODE:\n",
    "            current_episode_actions.append(a_np.copy())\n",
    "            \n",
    "        s_prime,_,done,info = gym.step(a_np,max_time=max_epi_sec)\n",
    "        reward = reward_long_jump(info)  #using long jump reward            \n",
    "        replay_buffer.put((s,a_np,reward,s_prime,done))\n",
    "        reward_total += reward \n",
    "        reward_forward += info['r_forward']\n",
    "        s = s_prime\n",
    "\n",
    "        # compute z_diff\n",
    "        x_diff = gym.env.get_p_body('torso')[0]\n",
    "        if x_diff > longest_jump:\n",
    "            longest_jump = x_diff\n",
    "        if done is True: break # terminate condition\n",
    "        \n",
    "        # Replay buffer\n",
    "        if replay_buffer.size() > buffer_warmup:\n",
    "             for _ in range(n_update_per_tick): \n",
    "                mini_batch = replay_buffer.sample(batch_size)\n",
    "                # Update critics\n",
    "                td_target = get_target(\n",
    "                    actor,\n",
    "                    critic_one_trgt,\n",
    "                    critic_two_trgt,\n",
    "                    gamma      = gamma,\n",
    "                    mini_batch = mini_batch,\n",
    "                    device     = device,\n",
    "                )\n",
    "                critic_one.train(td_target,mini_batch)\n",
    "                critic_two.train(td_target,mini_batch)\n",
    "                # Update actor\n",
    "                actor.train(\n",
    "                    critic_one,\n",
    "                    critic_two,\n",
    "                    target_entropy = -gym.a_dim,\n",
    "                    mini_batch     = mini_batch,\n",
    "                )\n",
    "                # Soft update of critics\n",
    "                critic_one.soft_update(tau=tau,net_target=critic_one_trgt)\n",
    "                critic_two.soft_update(tau=tau,net_target=critic_two_trgt)\n",
    "\n",
    "    # Compute x_diff\n",
    "    x_diff = gym.env.get_p_body('torso')[0]\n",
    "\n",
    "    # Print\n",
    "    if (epi_idx%print_every)==0:\n",
    "        epi_tick = tick\n",
    "        print (\"[%d/%d][%.1f%%]\"%(epi_idx,n_episode,100.0*(epi_idx/n_episode)))\n",
    "        print (\"  reward:[%.1f] x_diff:[%.3f] epi_len:[%d/%d]\"%\n",
    "               (reward_total,x_diff,epi_tick,max_epi_tick))\n",
    "               # replay_buffer.size(),actor.log_alpha.exp(),z_diff))\n",
    "    \n",
    "    # Evaluation\n",
    "    if (epi_idx%eval_every)==0:\n",
    "        if RENDER_EVAL: gym.init_viewer()\n",
    "        s = gym.reset()\n",
    "        reward_total = 0.0\n",
    "        for tick in range(max_epi_tick):\n",
    "            a,_ = actor(np2torch(s,device=device),SAMPLE_ACTION=False)\n",
    "            s_prime,reward,done,info = gym.step(torch2np(a),max_time=max_epi_sec)\n",
    "            reward_total += reward\n",
    "            if RENDER_EVAL and ((tick%5) == 0):\n",
    "                gym.render(\n",
    "                    TRACK_TORSO      = True,\n",
    "                    PLOT_WORLD_COORD = True,\n",
    "                    PLOT_TORSO_COORD = True,\n",
    "                    PLOT_SENSOR      = True,\n",
    "                    PLOT_CONTACT     = True,\n",
    "                    PLOT_TIME        = True,\n",
    "                )\n",
    "            s = s_prime\n",
    "            if RENDER_EVAL:\n",
    "                if not gym.is_viewer_alive(): break\n",
    "        if RENDER_EVAL: gym.close_viewer()\n",
    "        x_diff = gym.env.get_p_body('torso')[0]\n",
    "        z_diff = gym.env.get_p_body('torso')[2]\n",
    "        if x_diff > longest_jump:\n",
    "            longest_jump = x_diff\n",
    "        print (\"  [Eval] reward:[%.3f] x_diff:[%.3f] epi_len:[%d/%d] longest_jump:[%.3f]\"%\n",
    "               (reward_total,x_diff,tick,max_epi_tick,longest_jump))\n",
    "        \n",
    "    if TRACK_BEST_EPISODE and longest_jump > best_longest_jump:\n",
    "        best_longest_jump = longest_jump\n",
    "        best_episode_actions = current_episode_actions.copy()\n",
    "        best_episode_idx = epi_idx\n",
    "        best_pth_path = './result/weights/sac_%s/longjump/best_longjump%d.pth'%(gym.name.lower(),epi_idx)\n",
    "        torch.save(actor.state_dict(),best_pth_path)\n",
    "        print(f\" NEW BEST JUMP: {best_longest_jump:.3f} (Episode {epi_idx})\")\n",
    "\n",
    "        # Modify the training loop section\n",
    "    if TRACK_BEST_EPISODE and longest_jump > best_longest_jump:\n",
    "        best_longest_jump = longest_jump\n",
    "        best_episode_actions = current_episode_actions.copy()\n",
    "        best_episode_idx = epi_idx\n",
    "        best_pth_path = './result/weights/sac_%s/longjump/best_longjump%d.pth'%(gym.name.lower(),epi_idx)\n",
    "        torch.save(actor.state_dict(),best_pth_path)\n",
    "    \n",
    "    # Save video of the best episode\n",
    "        gym.init_viewer()\n",
    "        s = gym.reset()\n",
    "        frames = []\n",
    "        for action in best_episode_actions:\n",
    "            s_prime, _, _, _ = gym.step(action)\n",
    "            frame = gym.render(\n",
    "                TRACK_TORSO=True,\n",
    "                PLOT_WORLD_COORD=True,\n",
    "                PLOT_TORSO_COORD=True,\n",
    "                PLOT_SENSOR=True,\n",
    "                PLOT_CONTACT=True,\n",
    "                PLOT_TIME=True,\n",
    "                RETURN_FRAME=True  # Add this parameter to your render function\n",
    "            )\n",
    "            frames.append(frame)\n",
    "            if not gym.is_viewer_alive():\n",
    "                break\n",
    "        gym.close_viewer()\n",
    "    \n",
    "    # Save frames as MP4\n",
    "        video_path = f'./result/videos/sac_{gym.name.lower()}/longjump/best_jump_{epi_idx}.mp4'\n",
    "        os.makedirs(os.path.dirname(video_path), exist_ok=True)\n",
    "    \n",
    "    # Using imageio to save as MP4\n",
    "        with imageio.get_writer(video_path, fps=30) as writer:\n",
    "            for frame in frames:\n",
    "                writer.append_data(frame)\n",
    "    \n",
    "        print(f\" NEW BEST JUMP: {best_longest_jump:.3f} (Episode {epi_idx})\")\n",
    "        print(f\"  [Save] Best jump video saved to {video_path}\")\n",
    "\n",
    "    # Save network\n",
    "if (epi_idx%save_every)==0:\n",
    "    pth_path = './result/weights/sac_%s/longjump/episode_%d.pth'%(gym.name.lower(),epi_idx)\n",
    "    dir_path = os.path.dirname(pth_path)\n",
    "    if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
    "    if (epi_idx == 0) and REMOVE_PREV_FILES: # remove all existing files\n",
    "        files = os.listdir(path=dir_path)\n",
    "        print (\"  [Save] Remove existing [%d] pth files.\"%(len(files)))\n",
    "        for file in files: os.remove(os.path.join(dir_path,file))\n",
    "    torch.save(actor.state_dict(),pth_path)\n",
    "    print (\"  [Save] [%s] saved.\"%(pth_path))\n",
    "    \n",
    "    # Save best episode\n",
    "if TRACK_BEST_EPISODE and best_episode_actions:\n",
    "        best_action_path = './result/weights/sac_%s/longjump/best_jump_actions.pth'%gym.name.lower()\n",
    "        torch.save({\n",
    "            'episode_idx': best_episode_idx,\n",
    "            'longest_jump': best_longest_jump,\n",
    "            'actions': best_episode_actions\n",
    "        }, best_pth_path)\n",
    "        print (\"  [Save] Best jump actions saved to [%s].\"%(best_action_path))\n",
    "\n",
    "#def replay_best_episode():\n",
    "  #  best_pth_path = './result/weights/sac_%s/longjump/best_jump_actions.pth' % gym.name.lower()\n",
    "   # if not os.path.exists(best_pth_path):\n",
    "    #    print(\"No best episode found\")\n",
    "     #   return\n",
    "    \n",
    "    #best_data = torch.load(best_pth_path)\n",
    "    #print(f\"Replaying best jump (Length: {best_data['longest_jump']:.3f} from Episode {best_data['episode_idx']})\")\n",
    "    \n",
    "    #gym.init_viewer()\n",
    "    #s = gym.reset()\n",
    "    \n",
    "    #for action in best_data['actions']:\n",
    "    #    s_prime, _, _, _ = gym.step(action)\n",
    "     #   gym.render(\n",
    "     #       TRACK_TORSO=True,\n",
    "     #       PLOT_WORLD_COORD=True,\n",
    "      #      PLOT_TORSO_COORD=True,\n",
    "      ##      PLOT_SENSOR=True,\n",
    "      #      PLOT_CONTACT=True,\n",
    "         #   PLOT_TIME=True,\n",
    "       # )\n",
    "        #if not gym.is_viewer_alive():\n",
    "        #    break\n",
    "    \n",
    "    #gym.close_viewer()\n",
    "\n",
    "# After training completes\n",
    "if TRACK_BEST_EPISODE:\n",
    "    print(f\"\\nTraining complete! Best jump: {best_longest_jump:.3f} (Episode {best_episode_idx})\")\n",
    "    #replay_best_episode()  # Automatically play the best episode\n",
    "\n",
    "    \n",
    "print (\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272e03d-f38b-4487-8b0c-c36a9f3c4f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12235968622594\n",
      "1652\n",
      "[array([-2.  , -2.  , -2.  ,  0.99,  2.  ,  1.99,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -1.54,  1.99, -1.97, -2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -1.98,  0.54,  1.99,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -0.18,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.54,  2.  ,  1.99,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.99,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.66,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.76,  1.89,  2.  ,  2.  , -2.  ], dtype=float32), array([-1.95, -2.  , -2.  , -1.99,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  ,  1.97,  2.  , -1.98, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2., -2.,  2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.97, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.98, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.35, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.61, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.58, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.54, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.95, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.99, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.96,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-1.99, -2.  , -1.88,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2., -2., -2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2.  , -2.  , -1.46,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  , -2.  ,  1.19,  1.99,  1.99,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  ,  0.54,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -0.94,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -0.96,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.77,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.93,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.97,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.95,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([ 1.91,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.96,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 2.,  2., -2., -2.,  2.,  2., -2., -2.], dtype=float32), array([ 1.97,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 2.,  2., -2., -2.,  2.,  2., -2., -2.], dtype=float32), array([ 1.99,  2.  , -2.  , -2.  ,  1.99,  2.  , -2.  , -2.  ], dtype=float32), array([-0.35, -2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([-2.  , -2.  ,  1.99,  2.  , -2.  , -1.99,  2.  ,  2.  ], dtype=float32), array([-2., -2.,  2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2.  , -2.  ,  1.99,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.99,  2.  , -1.48, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.99, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.99, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.98, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.91, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.89, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2., -2.,  2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2.  , -2.  ,  1.84,  2.  , -1.94, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  , -1.75,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2., -2., -2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2., -2.,  2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2.  , -2.  , -2.  ,  0.71,  2.  ,  1.83,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  ,  0.02,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.62,  2.  ,  1.98,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.92,  1.99,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.97,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2., -2., -2., -2.,  2.,  2.,  2., -2.], dtype=float32), array([-1.59, -2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.94,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 0.86,  2.  , -1.99, -2.  ,  1.99,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.19,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.85,  2.  , -2.  , -1.99,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.78,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.81,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([-2. , -2. , -2. ,  0.2,  2. ,  2. ,  2. , -2. ], dtype=float32), array([-2.  , -2.  ,  1.98,  2.  , -1.99, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.79,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.98,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.96,  2.  , -1.98, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.61,  2.  , -1.95, -1.99,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.43,  2.  , -1.93, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.98,  2.  , -1.86, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.6 ,  2.  , -1.94, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.93,  1.99, -1.93, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.96,  2.  , -1.75, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  0.8 ,  2.  , -1.99, -1.99,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  , -1.96,  2.  , -1.81, -1.99,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  , -2.  ,  2.  , -1.98, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.99,  2.  , -1.96, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2. , -2. , -2. ,  0.8,  2. ,  2. ,  2. , -2. ], dtype=float32), array([-2.  , -2.  , -2.  , -0.19,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.65,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -2.  ,  2.  ,  1.99,  2.  , -2.  ], dtype=float32), array([-2., -2., -2., -2.,  2.,  2.,  2., -2.], dtype=float32), array([-2., -2., -2., -2.,  2.,  2.,  2., -2.], dtype=float32), array([ 2.  ,  2.  , -2.  , -2.  ,  2.  ,  1.99, -2.  , -2.  ], dtype=float32), array([ 1.99,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 2.,  2., -2., -2.,  2.,  2., -2., -2.], dtype=float32), array([ 2.,  2., -2., -2.,  2.,  2., -2., -2.], dtype=float32), array([ 2.,  2., -2., -2.,  2.,  2., -2., -2.], dtype=float32), array([-2.  , -2.  , -2.  , -0.26,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  ,  1.95,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.99,  2.  , -1.99, -1.99,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.98,  2.  , -1.98, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.96,  2.  , -1.95, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  2.  ,  2.  , -1.29, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.97,  2.  , -1.15, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.99,  2.  , -1.83, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  0.8 ,  2.  , -1.97, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  ,  1.61,  2.  , -1.99, -2.  ,  2.  ,  2.  ], dtype=float32), array([-2.  , -2.  , -0.54,  2.  , -2.  , -2.  ,  2.  ,  2.  ], dtype=float32), array([-2., -2., -2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2., -2., -2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2., -2., -2.,  2., -2., -2.,  2.,  2.], dtype=float32), array([-2.  , -2.  , -1.99,  2.  ,  1.26, -2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  ,  0.86,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  ,  0.36,  2.  ,  1.98,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.47,  2.  ,  1.97,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.77,  2.  ,  2.  ,  2.  , -2.  ], dtype=float32), array([-2.  , -2.  , -2.  , -1.99,  2.  ,  1.99,  2.  , -2.  ], dtype=float32), array([ 1.24, -2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.53, -2.  , -1.99, -1.99,  1.96,  1.97, -2.  , -2.  ], dtype=float32), array([ 1.67,  2.  , -2.  , -2.  ,  1.99,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.96,  2.  , -2.  , -2.  ,  2.  ,  2.  , -2.  , -2.  ], dtype=float32), array([ 1.9 ,  2.  , -2.  , -2.  ,  1.99,  2.  , -2.  , -2.  ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(best_longest_jump)\n",
    "print(best_episode_idx)\n",
    "print(best_episode_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea8d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "max_epi_sec  = 15.0 # maximum episode length in second\n",
    "max_epi_tick = int(max_epi_sec*gym.HZ) # maximum episode length in tick\n",
    "# Actor\n",
    "device     = 'cpu' # cpu / mps / cuda\n",
    "max_torque = 2.0\n",
    "init_alpha = 0.1\n",
    "lr_actor   = 0.0004\n",
    "lr_alpha   = 0.0003\n",
    "actor = ActorClass(\n",
    "    obs_dim    = gym.o_dim,\n",
    "    h_dims     = [256,256],\n",
    "    out_dim    = gym.a_dim,\n",
    "    max_out    = max_torque,\n",
    "    init_alpha = init_alpha,\n",
    "    lr_actor   = lr_actor,\n",
    "    lr_alpha   = lr_alpha,\n",
    "    device     = device,\n",
    ").to(device)\n",
    "\n",
    "max_length = 0.0 \n",
    "# Load pth\n",
    "pth_path = './result/weights/sac_%s/longjump/best_longjump%d.pth'%(gym.name.lower(),epi_idx)#'./result/weights/sac_%s/longjump/best_longjump%d.pth'%(gym.name.lower(),epi_idx)\n",
    "actor.load_state_dict(torch.load(pth_path,map_location=device))\n",
    "# Run\n",
    "gym.init_viewer()\n",
    "s = gym.reset()\n",
    "gym.viewer_pause() # pause\n",
    "print (\"   Viewer paused. Press [space] to resume.\")\n",
    "reward_total = 0.0\n",
    "for tick in range(max_epi_tick):\n",
    "    a,_ = actor(np2torch(s,device=device),SAMPLE_ACTION=False)\n",
    "    s_prime,reward,done, info = gym.step(torch2np(a),max_time=max_epi_sec)\n",
    "    gym.render(\n",
    "        TRACK_TORSO      = True,\n",
    "        PLOT_WORLD_COORD = True,\n",
    "        PLOT_TORSO_COORD = True,\n",
    "        PLOT_SENSOR      = True,\n",
    "        PLOT_CONTACT     = True,\n",
    "        PLOT_TIME        = True,\n",
    "    )\n",
    "    reward_total += reward\n",
    "    s = s_prime\n",
    "    if not gym.is_viewer_alive(): break\n",
    "gym.close_viewer()\n",
    "x_diff = gym.env.get_p_body('torso')[0]\n",
    "z_diff = gym.env.get_p_body('torso')[2]\n",
    "if x_diff > max_length:\n",
    "        max_height = x_diff\n",
    "print (\"  [Eval] reward:[%.3f] x_diff:[%.3f] epi_len:[%d/%d]\"%\n",
    "       (reward_total,x_diff,tick,max_epi_tick))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
